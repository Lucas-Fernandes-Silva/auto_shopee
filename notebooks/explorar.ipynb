{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4edf798",
   "metadata": {},
   "source": [
    "#Criar um script que faça:  \n",
    "#Pegue as nfe em xml do email  \n",
    "#Extrai os dados necessarios   \n",
    "#Tratar dados   \n",
    "#Remover materiais pesado E outras notas \n",
    "-TABUAS CABOQUINHO  \n",
    "-CIMENTRO VOTORAN  \n",
    "-Magalu   \n",
    "\n",
    "#Aplicador formula de taxas  \n",
    "#Inserir no template dos marketplaces\n",
    "\n",
    "Ultilizar api do bling para cadastro de itens   (quando tiver)\n",
    "\n",
    "\n",
    "Mercado LIVRE:50% do valor do produto (para produtos até R$ 12,50), R$ 6,25 (entre R$ 12,50 e R$ 29), R$ 6,50 (entre R$ 29 e R$ 50) e R$ 6,75 (entre R$ 50 e R$ 79)\n",
    "\n",
    "Comissão de Categoria Construção 12%\n",
    "\n",
    "\n",
    "SHOPE taxa de transação é sobre o total do produto então é 2% de taxa e 18 de comissão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from imap_tools import MailBox, AND\n",
    "from env import pwd, user\n",
    "from datetime import date, datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"notas/nfes/\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "with MailBox(\"imap.gmail.com\").login(\n",
    "    user,\n",
    "    pwd,\n",
    "    initial_folder=\"INBOX\",\n",
    ") as mailbox:\n",
    "    list_mail = mailbox.fetch(criteria=AND(date=date.today()))\n",
    "    for email in list_mail:\n",
    "        for anexo in email.attachments:\n",
    "            if anexo.filename.lower().endswith(\".xml\"):\n",
    "                file_path = os.path.join(save_folder, anexo.filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        f.write(anexo.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os XMLs em pastas por Emitente e extrai os produtos para um Excel\n",
    "\n",
    "pasta_origem = \"notas/nfes\"\n",
    "todos_produtos = []\n",
    "\n",
    "\n",
    "def extrai_dados(caminho_arquivo):\n",
    "    produtos = []\n",
    "    tree = ET.parse(caminho_arquivo)\n",
    "    root = tree.getroot()\n",
    "    ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "    data_str = root.find(\".//ns:ide/ns:dhEmi\", ns).text\n",
    "    data_emissao = datetime.fromisoformat(data_str)\n",
    "\n",
    "    natOp = root.find(\".//ns:ide/ns:natOp\", ns)\n",
    "    if (\n",
    "        natOp is not None\n",
    "        and natOp.text.strip().upper() == \"BONIFICACAO, DOACAO OU BRINDE\"\n",
    "    ):\n",
    "        return []\n",
    "\n",
    "    for det in root.findall(\".//ns:det\", ns):\n",
    "        produto = {}\n",
    "        temp_codigo = det.find(\"./ns:prod/ns:cProd\", ns).text\n",
    "        if \"-\" not in temp_codigo:\n",
    "            produto[\"Codigo Produto\"] = temp_codigo\n",
    "        produto[\"Descrição\"] = det.find(\"./ns:prod/ns:xProd\", ns).text\n",
    "        produto[\"Valor_unitário\"] = det.find(\"./ns:prod/ns:vUnCom\", ns).text\n",
    "        produto[\"Código de Barras\"] = det.find(\"./ns:prod/ns:cEAN\", ns).text\n",
    "        produto[\"Sku\"] = produto[\"Código de Barras\"]\n",
    "        if produto[\"Sku\"] == \"SEM GTIN\":\n",
    "            produto[\"Sku\"] = produto[\"Descrição\"]\n",
    "        produto[\"Fornecedor\"] = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "        produto[\"Data Emissão\"] = data_emissao\n",
    "\n",
    "        produtos.append(produto)\n",
    "    return produtos\n",
    "\n",
    "\n",
    "# Percorre todos os arquivos da pasta\n",
    "for arquivo in os.listdir(pasta_origem):\n",
    "    if arquivo.lower().endswith(\".xml\"):\n",
    "        caminho_arquivo = os.path.join(pasta_origem, arquivo)\n",
    "\n",
    "        try:\n",
    "            # Abre e parseia o XML\n",
    "            tree = ET.parse(caminho_arquivo)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Define namespace\n",
    "            ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "\n",
    "            # Busca o CNPJ do emitente\n",
    "            cnpj_emitente = root.find(\".//ns:emit/ns:CNPJ\", ns)\n",
    "            cnpj_emitente\n",
    "            if cnpj_emitente is None:\n",
    "                print(f\"⚠️ CNPJ não encontrado em {arquivo}\")\n",
    "                continue\n",
    "\n",
    "            cnpj_emitente = cnpj_emitente.text\n",
    "\n",
    "            produtos = extrai_dados(caminho_arquivo)\n",
    "            todos_produtos.extend(produtos)\n",
    "\n",
    "            emitente = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "\n",
    "            pasta_destino = os.path.join(\"notas/\")\n",
    "\n",
    "            # Cria a pasta se não existir\n",
    "            os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "            # Copia o arquivo para a pasta\n",
    "            shutil.copy(caminho_arquivo, pasta_destino)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" {arquivo}: {e}\")\n",
    "\n",
    "\n",
    "fornecedores_pesados = [\n",
    "    \"IND E COM DE TUBOS E CONEXOES FORT.COM\",\n",
    "    \"VOTORANTIM CIMENTOS SA\",\n",
    "    \"CABOQUINHO MATERIAIS PARA CONSTRUCAO\",\n",
    "]\n",
    "\n",
    "\n",
    "produtos = pd.DataFrame(todos_produtos)\n",
    "produtos = produtos[~produtos[\"Fornecedor\"].isin(fornecedores_pesados)]\n",
    "produtos = produtos.sort_values(by=\"Data Emissão\", ascending=False)\n",
    "\n",
    "produtos = produtos.drop_duplicates(subset=\"Codigo Produto\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos[\"Fornecedor\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f384208",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "    \"(KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d981c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_excel(\"upseller_template.xlsx\")\n",
    "produtos = read[-1:]\n",
    "\n",
    "\n",
    "for index, produto in produtos.iterrows():\n",
    "    # fornecedor = produto['Fornecedor']\n",
    "    # codigo_produto = produto['Codigo Produto']\n",
    "    # descricao = produto['Descrição']\n",
    "    try:\n",
    "        #     if fornecedor == 'CONSTRUDIGI DISTRIBUIDORA DE MATERIAIS PARA CONSTRUCAO LTDA':\n",
    "        #         url = f'https://www.construdigi.com.br/produto/{codigo_produto}/{descricao}'\n",
    "        #     elif fornecedor == 'M.S.B. COMERCIO DE MATERIAIS PARA CONSTRUCAO':\n",
    "        #         url = f'https://msbitaqua.com.br/produto/{codigo_produto}/{descricao}'\n",
    "        #     elif fornecedor == \"CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU\":\n",
    "        #         url = f'https://www.construja.com.br/produto/{codigo_produto}/{descricao}'\n",
    "        #     else:\n",
    "        #         print('Indisponivel')\n",
    "        #         continue\n",
    "\n",
    "        url = \"https://construja.com.br/produto/101223/estrela-tapa-furo-ll-20mm\"\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        script = soup.find(\"script\", type=\"application/json\")\n",
    "        data = json.loads(script.string) if script else {}\n",
    "\n",
    "        extrai = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"produto\", {})\n",
    "        comprimento = extrai.get(\"comprimento\")\n",
    "\n",
    "        url_img = (\n",
    "            data.get(\"props\", {})\n",
    "            .get(\"pageProps\", {})\n",
    "            .get(\"seo\", {})\n",
    "            .get(\"imageUrl\", \"Não disponivel\")\n",
    "        )\n",
    "        marca = next(\n",
    "            (\n",
    "                p.get(\"desc\")\n",
    "                for p in extrai.get(\"dimensoes\", [])\n",
    "                if p.get(\"label\") == \"MARCA\"\n",
    "            ),\n",
    "            \"Não disponível\",\n",
    "        )\n",
    "        categoria = next(\n",
    "            (\n",
    "                p.get(\"desc\")\n",
    "                for p in extrai.get(\"dimensoes\", [])\n",
    "                if p.get(\"label\") == \"SUB CATEGORIA\"\n",
    "            ),\n",
    "            \"Não disponível\",\n",
    "        )\n",
    "        print(categoria)\n",
    "        peso = extrai.get(\"pesoBruto\", \"Não disponível\")\n",
    "        if codigo_barras == \"SEM GTIN\":\n",
    "            codigo_barras = extrai.get(\"codBarra\", \"SEM GTIN\")\n",
    "        produtos.at[index, \"Código de Barras\"] = codigo_barras\n",
    "        produtos.at[index, \"Peso\"] = peso\n",
    "        produtos.at[index, \"Marca\"] = marca\n",
    "        produtos.at[index, \"Url Imagem\"] = url_img\n",
    "\n",
    "        print(produto[\"Descrição\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# === 1. Carregar o arquivo ===\n",
    "df = pd.read_excel(\"produtos.xlsx\")\n",
    "\n",
    "\n",
    "# === 2. Função para limpar e normalizar texto ===\n",
    "def limpar_texto(txt):\n",
    "    if not isinstance(txt, str):\n",
    "        return \"\"\n",
    "    # Remove acentos\n",
    "    txt = unicodedata.normalize(\"NFD\", txt)\n",
    "    txt = txt.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    # Converte para maiúsculas\n",
    "    txt = txt.upper()\n",
    "    # Remove caracteres especiais\n",
    "    txt = re.sub(r\"[^A-Z0-9 ]\", \"\", txt)\n",
    "    # Remove espaços duplicados\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "    return txt\n",
    "\n",
    "\n",
    "# === 3. Lista de marcas fixas (forçadas a fazer parte da análise) ===\n",
    "marcas_adicionais = [\n",
    "    \"SHIVA\",\n",
    "    \"BRASCOLA\",\n",
    "    \"FERTAK\",\n",
    "    \"NATICON\",\n",
    "    \"NOBRE\",\n",
    "    \"ADELBRAS\",\n",
    "    \"STA MARINA\",\n",
    "    \"FIRMEZA\",\n",
    "    \"OLIPLAS\",\n",
    "    \"STAM\",\n",
    "    \"R.C.A\",\n",
    "    \"CORONA\",\n",
    "    \"TOP FIO\",\n",
    "    \"MAKITA\",\n",
    "    \"REXON\",\n",
    "    \"SOPRANO\",\n",
    "    \"FAST LUB\",\n",
    "    \"ACQUA\",\n",
    "    \"KIAN\",\n",
    "    \"SOUDAL\",\n",
    "    \"DEPLAST\",\n",
    "    \"TATU\",\n",
    "    \"GRENDHA\",\n",
    "    \"PANASONIC\",\n",
    "    \"PAULICEIA\",\n",
    "    \"MORIA\",\n",
    "    \"ALLTAPE\",\n",
    "    \"PLASTILIT\",\n",
    "    \"TITANIUM\",\n",
    "    \"FERRARI\",\n",
    "    \"NEGREIRA\",\n",
    "    \"RADIAL\",\n",
    "    \"BLUMENAU\",\n",
    "    \"J.F METAIS\",\n",
    "    \"ART METAIS\",\n",
    "    \"LONAX\",\n",
    "    \"GHEL PLUS\",\n",
    "    \"CHEMICOLOR\",\n",
    "    \"SANY\",\n",
    "    \"PROAQUA\",\n",
    "    \"BICROM\",\n",
    "    \"WAGO\",\n",
    "    \"TECHNA\",\n",
    "    \"METASUL\",\n",
    "    \"GARAPEIRA\",\n",
    "    \"ROCO\",\n",
    "    \"PRO FOAM\",\n",
    "    \"DURACELL\",\n",
    "    \"POLIBEL\",\n",
    "    \"AGELUX\",\n",
    "    \"REMOX\",\n",
    "    \"RORATO\",\n",
    "    \"WAVES\",\n",
    "    \"LEGRAND\",\n",
    "    \"PAPAIZ\",\n",
    "    \"AGELUZ\",\n",
    "    \"IMPERIAL\",\n",
    "    \"HYDRA\",\n",
    "    \"KITUBO\",\n",
    "    \"NETTE\",\n",
    "    \"SANLIMP\",\n",
    "    \"EMA METAIS\",\n",
    "    \"M&M\" \"BEARS\",\n",
    "    \"ADTEX\",\n",
    "    \"GALO\",\n",
    "    \"PEGAFORTE\",\n",
    "    \"EMAVE\",\n",
    "    \"ELGIN\",\n",
    "    \"LUCONI\",\n",
    "    \"VEGA\",\n",
    "    \"MUNDIAL\",\n",
    "    \"DELTA\",\n",
    "    \"COBRECOM\",\n",
    "    \"PLASTBIG\",\n",
    "    \"FERE\",\n",
    "    \"SATA\",\n",
    "    \"ALUMBRA\",\n",
    "    \"FIOLUX\",\n",
    "    \"PACETTA\",\n",
    "    \"ITAMBE\",\n",
    "    \"PEXCEL\",\n",
    "    \"EMAVA\",\n",
    "    \"KADESH\",\n",
    "    \"IBERE\",\n",
    "    \"GOLD\",\n",
    "    \"PERLEX\",\n",
    "    \"IMA\",\n",
    "    \"SAFETY\",\n",
    "    \"PIAL\",\n",
    "    \"PLASTIK\",\n",
    "    \"OUROLUX\",\n",
    "    \"LED BEE\",\n",
    "    \"BELZER\",\n",
    "    \"PROTEG\",\n",
    "    \"NASTRO\",\n",
    "    \"FJ FERR\",\n",
    "    \"SAO RAFAEL\",\n",
    "    \"STILLUS\",\n",
    "    \"FLASH LIMP\",\n",
    "    \"ZUMPLAST\",\n",
    "    \"REDY\",\n",
    "    \"PRIMETECH\",\n",
    "    \"SECALUX\",\n",
    "    \"PLASTIC\",\n",
    "    \"SUPER BONDER\",\n",
    "    \"ARTPLAS\",\n",
    "    \"FABER CASTELL\",\n",
    "    \"GUARANI\",\n",
    "    \"DEWALT\",\n",
    "    \"ALUREM\",\n",
    "    \"PERFIX \",\n",
    "    \"STELL\",\n",
    "    \"FERROX\",\n",
    "    \"USAF\",\n",
    "    \"INJET\",\n",
    "    \"CMK\",\n",
    "    \"BEARS\",\n",
    "    \"MINASUL\",\n",
    "    \"DEGOMASTER\",\n",
    "    \"SIENA\",\n",
    "]\n",
    "marcas_adicionais = [limpar_texto(m) for m in marcas_adicionais]\n",
    "\n",
    "\n",
    "# === 4. Dicionário de sinônimos / variações ===\n",
    "mapa_variacoes = {\n",
    "    \"TRAMONTINA\": [\n",
    "        \"TRAMON\",\n",
    "        \"TRAMONTINA\",\n",
    "        \"TRAMONTINA ELE\",\n",
    "        \"TRAMONTINA GARI\",\n",
    "        \"TRAMONTINA MULT\",\n",
    "        \"TRAM\",\n",
    "    ],\n",
    "    \"JOMARCA\": [\"JOMARCA\", \"JOMARC\", \"JOMARCA JMC\", \"JMC\"],\n",
    "    \"NEW FIX\": [\n",
    "        \"NEW FIX\",\n",
    "        \"NEWFIX\",\n",
    "        \"NEW-FIX\",\n",
    "        \"NEW F\",\n",
    "        \"PARAF CHIPBOARD CHATA PHS\",\n",
    "        \"PARAF SEX.ROS.SOBERBA\",\n",
    "    ],\n",
    "    \"NOVA\": [\"NOVA TINTAS\", \"NOVA\"],\n",
    "    \"DRYKO\": [\"DRYKO\", \"DRYKOPRIMER\"],\n",
    "    \"SIKA\": [\"SIKATOP\", \"SIKA\"],\n",
    "    \"BRASFORT\": [\"BRASF\", \"BRASFORT\"],\n",
    "    \"ILUMI\": [\"ILUM\", \"ILUMI\"],\n",
    "    \"DENVER\": [\n",
    "        \"DENVER\",\n",
    "        \"DENVERIMPER\",\n",
    "        \"DENVERLAJE\",\n",
    "        \"DENVERTEC\",\n",
    "        \"DENVERCRILL\",\n",
    "        \"DENVERFITA\",\n",
    "        \"DENVERFIX\",\n",
    "    ],\n",
    "    \"THOMPSOM\": [\"THOMPSOM\", \"THOMP\"],\n",
    "    \"PEGAFORTE\": [\"PEGAFORTE\", \"PEGA FORTE\"],\n",
    "    \"CALHA FORTE\": [\"CALHA FORTE\", \"CALHA FORT\"],\n",
    "    \"VEDACIT\": [\"VEDACIT\", \"BIANCO\"],\n",
    "    \"LORENZETTI\": [\"LOREN\", \"LORENZETTI\", \"ORIG.L&C D\", \".PMR D.\", \".L&C \"],\n",
    "    \"KADESH\": [\"BOT FLEX ELASTICO PRETA BI\"],\n",
    "}\n",
    "\n",
    "\n",
    "# === 5. Montar lista final de marcas conhecidas ===\n",
    "marcas_planilha = df[\"Marca\"].dropna().unique().tolist()\n",
    "marcas_planilha.remove(\"5+\")\n",
    "marcas_planilha = [\n",
    "    limpar_texto(m) for m in marcas_planilha if isinstance(m, str) and m.strip()\n",
    "]\n",
    "\n",
    "# Combinar todas\n",
    "marcas = list(set(marcas_planilha + marcas_adicionais))\n",
    "\n",
    "# Adicionar também as variações do mapa\n",
    "for marca_principal, variacoes in mapa_variacoes.items():\n",
    "    marcas.append(marca_principal)\n",
    "    marcas.extend([limpar_texto(v) for v in variacoes])\n",
    "\n",
    "marcas = list(set(marcas))\n",
    "\n",
    "\n",
    "# === 7. Função para detectar marca na descrição ===\n",
    "def detectar_marca(descricao):\n",
    "    desc_limpa = limpar_texto(descricao)\n",
    "\n",
    "    # Verifica variações conhecidas primeiro\n",
    "    for marca_padrao, variacoes in mapa_variacoes.items():\n",
    "        for v in variacoes:\n",
    "            if limpar_texto(v) in desc_limpa:\n",
    "                return marca_padrao\n",
    "\n",
    "    # Caso não encontre nas variações, busca direta na lista geral\n",
    "    for marca in marcas:\n",
    "        if marca and marca in desc_limpa:\n",
    "            return marca\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "df_filtrado = df.copy()\n",
    "\n",
    "# === 8. Detectar e preencher marcas ausentes ===\n",
    "df_filtrado[\"Marca Detectada\"] = df_filtrado[\"Descrição\"].apply(detectar_marca)\n",
    "\n",
    "# Preenche apenas onde está vazio\n",
    "df_filtrado[\"Marca\"] = df_filtrado[\"Marca\"].fillna(df_filtrado[\"Marca Detectada\"])\n",
    "\n",
    "df_filtrado[\"Marca\"] = df_filtrado[\"Marca\"].fillna(\"GENÉRICO\")\n",
    "# Atualiza no dataframe principal\n",
    "df.update(df_filtrado)\n",
    "\n",
    "\n",
    "# === 9. Salvar resultado ===\n",
    "df.to_excel(\"produtos_com_marcas.xlsx\", index=False)\n",
    "\n",
    "# === 10. Relatório simples ===\n",
    "print(\"✅ Processamento concluído!\")\n",
    "print(f\"Total de produtos analisados: {len(df_filtrado)}\")\n",
    "print(\n",
    "    f\"Marcas detectadas automaticamente: {df_filtrado['Marca Detectada'].notna().sum()}\"\n",
    ")\n",
    "\n",
    "# Top 10 marcas mais detectadas\n",
    "print(\"\\nTop marcas detectadas:\")\n",
    "print(df_filtrado[\"Marca Detectada\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"pai_filho_variantes.xlsx\")\n",
    "\n",
    "\n",
    "# --- Função para normalizar ---\n",
    "def normalizar(texto):\n",
    "    texto = str(texto).lower().strip()\n",
    "    texto = (\n",
    "        unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    )\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto)\n",
    "    return texto\n",
    "\n",
    "\n",
    "df[\"chave_norm\"] = df[\"chave\"].apply(normalizar)\n",
    "\n",
    "\n",
    "# --- Função para encontrar a base e variação dentro de um grupo ---\n",
    "def extrair_base_variacao(grupo_df):\n",
    "    textos = grupo_df[\"chave_norm\"].tolist()\n",
    "    palavras = [set(t.split()) for t in textos]\n",
    "\n",
    "    comuns = set.intersection(*palavras)\n",
    "    bases, variacoes = [], []\n",
    "    for texto in textos:\n",
    "        palavras_texto = texto.split()\n",
    "        variacao = [p for p in palavras_texto if p not in comuns]\n",
    "        base = [p for p in palavras_texto if p in comuns]\n",
    "        bases.append(\" \".join(base))\n",
    "        variacoes.append(\" \".join(variacao))\n",
    "\n",
    "    grupo_df[\"base\"] = bases\n",
    "    grupo_df[\"variacao\"] = variacoes\n",
    "    return grupo_df\n",
    "\n",
    "\n",
    "# --- Aplica por grupo ---\n",
    "df_resultado = (\n",
    "    df.groupby(\"ID_Variacao\", group_keys=False)\n",
    "    .apply(lambda g: extrair_base_variacao(g.copy()))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_resultado.to_excel(\"base_nome.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab5933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Função para normalizar textos ---\n",
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).upper().strip()\n",
    "    texto = \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", texto)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "    return texto\n",
    "\n",
    "\n",
    "def limpar_texto(txt):\n",
    "    if not isinstance(txt, str):\n",
    "        return \"\"\n",
    "    txt = unicodedata.normalize(\"NFD\", txt)\n",
    "    txt = txt.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    txt = txt.upper()\n",
    "    txt = re.sub(r\"[^A-Z0-9 ]\", \"\", txt)\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "    return txt\n",
    "\n",
    "\n",
    "# --- Carrega o Excel ---\n",
    "df = pd.read_excel(\"pai_filho_variantes.xlsx\")\n",
    "df = df[0:20]\n",
    "\n",
    "\n",
    "# --- Cria chave composta ---\n",
    "df[\"Chave\"] = df[\"Descrição\"].apply(normalizar)\n",
    "\n",
    "# --- Ordena ---\n",
    "df = df.sort_values(by=[\"ID_Variacao\", \"Tipo\"], ascending=[True, True]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "# --- Função com controle de sensibilidade ---\n",
    "\n",
    "\n",
    "def parte_comum(strings, sensibilidade):\n",
    "    if not strings:\n",
    "        return \"\"\n",
    "    base = strings[0]\n",
    "    for s in strings[1:]:\n",
    "        s = limpar_texto(s)\n",
    "        tokens_base = set(base.upper().split())\n",
    "        tokens_s = set(s.upper().split())\n",
    "\n",
    "        comum_tokens = tokens_base & tokens_s\n",
    "        comum = \" \".join(comum_tokens)\n",
    "        proporcao = fuzz.token_set_ratio(base, s) / 100\n",
    "\n",
    "        if proporcao >= sensibilidade:\n",
    "            base = comum\n",
    "        else:\n",
    "            limite = max(1, int(len(comum_tokens) * sensibilidade))\n",
    "            base = \" \".join(list(comum_tokens)[:limite])\n",
    "\n",
    "    return base.strip()\n",
    "\n",
    "\n",
    "print(\"🧩 Gerando colunas base e variante...\")\n",
    "df[\"Base\"] = \"\"\n",
    "df[\"Variante\"] = \"\"\n",
    "\n",
    "for gid, grupo in df.groupby(\"ID_Variacao\", group_keys=False):\n",
    "    chaves = grupo[\"Chave\"].tolist()\n",
    "    comum = parte_comum(chaves, 0.1)\n",
    "\n",
    "    for idx, linha in grupo.iterrows():\n",
    "        texto = linha[\"Chave\"]\n",
    "        variante = texto.replace(comum, \"\").strip()\n",
    "        df.at[idx, \"Base\"] = comum\n",
    "        df.at[idx, \"Variante\"] = variante\n",
    "\n",
    "df[[\"Base\", \"Variante\", \"ID_Variacao\"]]\n",
    "\n",
    "# # --- Salva ---\n",
    "# arquivo_saida = \"base_nome.xlsx\"\n",
    "# df.to_excel(arquivo_saida, index=False)\n",
    "\n",
    "# print(\"✅ Agrupamento concluído com sucesso!\")\n",
    "# print(f\"📂 Arquivo salvo como: {arquivo_saida}\")\n",
    "# print(f\"📦 Total de grupos de variações criados: {grupo_id - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"CHAVE PHILLIPS CRV TOCO C/PI 1/4X11/2 FAMASTIL FERRAMENTAS MANUAIS E ACESSORIOS\"\n",
    "b = \"CHAVE FENDA TOCO CRV C/PI 3/16X11/2 FOX/FAMASTIL FERRAMENTAS MANUAIS E ACESSORIOS\"\n",
    "\n",
    "\n",
    "# print(f\"Similarity score: {fuzz.token_sort_ratio(a, b)}\")\n",
    "\n",
    "# print(process.extract(collection, scorer=fuzz.ratio))\n",
    "\n",
    "\n",
    "set_a = set(a.split())\n",
    "set_b = set(b.split())\n",
    "\n",
    "semelhantes = set_a.intersection(set_b)\n",
    "diferentes_a = set_a - set_b\n",
    "diferentes_b = set_b - set_a\n",
    "\n",
    "print(\"Iguais:\", semelhantes)\n",
    "print(\"Só em A:\", diferentes_a)\n",
    "print(\"Só em B:\", diferentes_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).upper().strip()\n",
    "    texto = \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", texto)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "    texto = re.sub(r\"[^A-Z0-9 ]\", \"\", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    return texto\n",
    "\n",
    "\n",
    "def similaridade_media(strings):\n",
    "    \"\"\"Calcula a similaridade média do grupo\"\"\"\n",
    "    pares = list(itertools.combinations(strings, 2))\n",
    "    if not pares:\n",
    "        return 1.0\n",
    "    scores = [fuzz.token_set_ratio(a, b) / 100 for a, b in pares]\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "\n",
    "def parte_comum(strings, sensibilidade=0.7):\n",
    "    \"\"\"Extrai tokens comuns entre descrições, ignorando tamanhos e códigos numéricos\"\"\"\n",
    "    if not strings:\n",
    "        return \"\"\n",
    "\n",
    "    # Tokeniza e normaliza\n",
    "    token_lists = [normalizar(s).split() for s in strings]\n",
    "    todas_palavras = set(sum(token_lists, []))\n",
    "\n",
    "    # Remove tokens que são medidas ou números (ex: 3/4, 48X50)\n",
    "    def eh_medida(p):\n",
    "        return bool(re.match(r\"^\\d+[Xx/]\\d+$\", p)) or p.isdigit()\n",
    "\n",
    "    todas_palavras = {p for p in todas_palavras if not eh_medida(p)}\n",
    "\n",
    "    contagem = Counter()\n",
    "    for palavra in todas_palavras:\n",
    "        for tokens in token_lists:\n",
    "            similar = any(fuzz.ratio(palavra, t) / 100 >= sensibilidade for t in tokens)\n",
    "            if similar:\n",
    "                contagem[palavra] += 1\n",
    "\n",
    "    limite = max(1, int(len(strings) * 0.8))\n",
    "    comuns = [w for w, c in contagem.items() if c >= limite]\n",
    "\n",
    "    primeira = token_lists[0]\n",
    "    base_ordenada = [\n",
    "        t\n",
    "        for t in primeira\n",
    "        if any(fuzz.ratio(t, w) / 100 >= sensibilidade for w in comuns)\n",
    "    ]\n",
    "\n",
    "    base = \" \".join(base_ordenada).strip()\n",
    "    base = re.sub(r\"\\b\\d+([Xx/]\\d+)?\\b\", \"\", base).strip()\n",
    "    base = re.sub(r\"\\s+\", \" \", base).strip()\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "# --- Carrega base ---\n",
    "df = pd.read_excel(\"pai_filho_variantes.xlsx\")\n",
    "df = df.head(20)\n",
    "\n",
    "\n",
    "# --- Normaliza chave ---\n",
    "df[\"Chave\"] = np.where(\n",
    "    df[\"Categoria\"].isin([\"CONEXÕES ESGOTO\", \"CONEXÕES ÁGUA\"]),\n",
    "    df[\"Categoria\"].apply(normalizar) + \" \" + df[\"Descrição\"].apply(normalizar),\n",
    "    df[\"Descrição\"].apply(normalizar),\n",
    ")\n",
    "\n",
    "# --- Ordena ---\n",
    "df = df.sort_values(by=[\"ID_Variacao\", \"Tipo\"], ascending=[True, True]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "# --- Cria colunas ---\n",
    "df[\"Base\"] = \"\"\n",
    "df[\"Variante\"] = \"\"\n",
    "\n",
    "\n",
    "for gid, grupo in tqdm(df.groupby(\"ID_Variacao\", group_keys=False)):\n",
    "    chaves = grupo[\"Chave\"].tolist()\n",
    "    media = similaridade_media(chaves)\n",
    "\n",
    "    # Sensibilidade dinâmica\n",
    "    if media >= 0.9:\n",
    "        sensibilidade = 0.85\n",
    "    elif media >= 0.8:\n",
    "        sensibilidade = 0.75\n",
    "    else:\n",
    "        sensibilidade = 0.65\n",
    "\n",
    "    comum = parte_comum(chaves, sensibilidade)\n",
    "\n",
    "    # Se o grupo tiver só um item, usa a descrição completa como base\n",
    "    if len(grupo) == 1 or not comum:\n",
    "        comum = normalizar(grupo[\"Descrição\"].iloc[0])\n",
    "\n",
    "    for idx, linha in grupo.iterrows():\n",
    "        texto = linha[\"Chave\"]\n",
    "        variante = texto.replace(comum, \"\").strip()\n",
    "        df.at[idx, \"Base\"] = comum\n",
    "        df.at[idx, \"Variante\"] = variante\n",
    "\n",
    "\n",
    "# --- Resultado ---\n",
    "df[[\"ID_Variacao\", \"Descrição\", \"Base\", \"Variante\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97daddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Codigo Produto                                  Descrição  \\\n",
      "0             186124                 FITA DUREX TRANSP 12X50 3M   \n",
      "1             170124        BROCA VIDEA SDS PLUS 10,0X160 IRWIN   \n",
      "2             188335  RATOEIRA GAIOLA C/MOLA PEQUENA* CHACONFER   \n",
      "3             188334     RATOEIRA GAIOLA C/MOLA MEDIA CHACONFER   \n",
      "4             188333    RATOEIRA GAIOLA C/MOLA GRANDE CHACONFER   \n",
      "...              ...                                        ...   \n",
      "4096           89389            BROCA IRWIN WIDEA PLUS 10,0X210   \n",
      "4097          347787          PINO MACHO REDY 2P 10A POTE CORES   \n",
      "4098          373710      FURAD B&D IMPACTO 3/8 220V TM500 560W   \n",
      "4099          279331   TUBO CORR PLASTIK ESGOTO 100MM BARRA 6MT   \n",
      "4100          279323   TUBO CORR PLASTIK ESGOTO  50MM BARRA 6MT   \n",
      "\n",
      "      Valor_unitário Código de Barras  \\\n",
      "0              3.544   00000078930469   \n",
      "1             13.282   00042526940767   \n",
      "2             19.115    0040141762252   \n",
      "3             23.950    0040141762269   \n",
      "4             28.990    0040141762276   \n",
      "...              ...              ...   \n",
      "4096          12.936         SEM GTIN   \n",
      "4097           1.520         SEM GTIN   \n",
      "4098         121.745         SEM GTIN   \n",
      "4099          36.990         SEM GTIN   \n",
      "4100          26.590         SEM GTIN   \n",
      "\n",
      "                                           Sku  \\\n",
      "0                               00000078930469   \n",
      "1                               00042526940767   \n",
      "2                                0040141762252   \n",
      "3                                0040141762269   \n",
      "4                                0040141762276   \n",
      "...                                        ...   \n",
      "4096           BROCA IRWIN WIDEA PLUS 10,0X210   \n",
      "4097         PINO MACHO REDY 2P 10A POTE CORES   \n",
      "4098     FURAD B&D IMPACTO 3/8 220V TM500 560W   \n",
      "4099  TUBO CORR PLASTIK ESGOTO 100MM BARRA 6MT   \n",
      "4100  TUBO CORR PLASTIK ESGOTO  50MM BARRA 6MT   \n",
      "\n",
      "                                      Fornecedor        Data Emissão  \\\n",
      "0       CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU 2025-07-08 07:47:00   \n",
      "1       CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU 2025-04-15 07:12:00   \n",
      "2       CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU 2024-10-01 05:36:00   \n",
      "3       CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU 2025-03-06 06:51:00   \n",
      "4       CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU 2025-03-06 06:51:00   \n",
      "...                                          ...                 ...   \n",
      "4096  MJR CUNHA DISTRIBUIDORA DE MAT.CONSTR LTDA 2020-06-09 05:20:18   \n",
      "4097  MJR CUNHA DISTRIBUIDORA DE MAT.CONSTR LTDA 2020-03-11 05:03:06   \n",
      "4098  MJR CUNHA DISTRIBUIDORA DE MAT.CONSTR LTDA 2020-01-28 03:08:19   \n",
      "4099  MJR CUNHA DISTRIBUIDORA DE MAT.CONSTR LTDA 2020-01-24 04:53:28   \n",
      "4100  MJR CUNHA DISTRIBUIDORA DE MAT.CONSTR LTDA 2020-01-21 04:30:21   \n",
      "\n",
      "           NCM      Marca   Peso  ... Altura  Comprimento  \\\n",
      "0     39191010         3M  0.032  ...    1.3         10.0   \n",
      "1     82075011      IRWIN  0.070  ...    1.5          1.5   \n",
      "2     73262000  CHACONFER  0.768  ...   12.0         15.0   \n",
      "3     73262000  CHACONFER  0.632  ...   12.0         15.0   \n",
      "4     73262000  CHACONFER  0.685  ...   15.0         16.0   \n",
      "...        ...        ...    ...  ...    ...          ...   \n",
      "4096  82075011      IRWIN  1.000  ...    NaN          NaN   \n",
      "4097  85366910       REDY  1.000  ...    NaN          NaN   \n",
      "4098  84672100         BD  1.000  ...    NaN          NaN   \n",
      "4099  39172300    PLASTIK  1.000  ...    NaN          NaN   \n",
      "4100  39172300    PLASTIK  1.000  ...    NaN          NaN   \n",
      "\n",
      "                               Categoria  \\\n",
      "0                         FITAS ADESIVAS   \n",
      "1                                 BROCAS   \n",
      "2                            DIVERSOS-UD   \n",
      "3                            DIVERSOS-UD   \n",
      "4                            DIVERSOS-UD   \n",
      "...                                  ...   \n",
      "4096                              BROCAS   \n",
      "4097         TOMADAS INTERRUPTORES PINOS   \n",
      "4098               FERRAMENTAS ELÉTRICAS   \n",
      "4099                              BROCAS   \n",
      "4100  EQUIPAMENTO DE PROTEÇÃO INDIVIDUAL   \n",
      "\n",
      "                                         Chave ID_Variacao   Tipo  \\\n",
      "0                   FITA DUREX TRANSP 12X50 3M         223    PAI   \n",
      "1           BROCA VIDEA SDS PLUS 100X160 IRWIN         299  FILHO   \n",
      "2      RATOEIRA GAIOLA CMOLA PEQUENA CHACONFER         367  FILHO   \n",
      "3        RATOEIRA GAIOLA CMOLA MEDIA CHACONFER         367    PAI   \n",
      "4       RATOEIRA GAIOLA CMOLA GRANDE CHACONFER         367  FILHO   \n",
      "...                                        ...         ...    ...   \n",
      "4096            BROCA IRWIN WIDEA PLUS 100X210        2646  FILHO   \n",
      "4097         PINO MACHO REDY 2P 10A POTE CORES        2654    PAI   \n",
      "4098       FURAD BD IMPACTO 38 220V TM500 560W        2677    PAI   \n",
      "4099  TUBO CORR PLASTIK ESGOTO 100MM BARRA 6MT        2679    PAI   \n",
      "4100   TUBO CORR PLASTIK ESGOTO 50MM BARRA 6MT        2685    PAI   \n",
      "\n",
      "                                       SKU_Pai  \\\n",
      "0                               00000078930469   \n",
      "1                                7897095032794   \n",
      "2                                0040141762269   \n",
      "3                                0040141762269   \n",
      "4                                0040141762269   \n",
      "...                                        ...   \n",
      "4096                             7897095040355   \n",
      "4097         PINO MACHO REDY 2P 10A POTE CORES   \n",
      "4098     FURAD B&D IMPACTO 3/8 220V TM500 560W   \n",
      "4099  TUBO CORR PLASTIK ESGOTO 100MM BARRA 6MT   \n",
      "4100  TUBO CORR PLASTIK ESGOTO  50MM BARRA 6MT   \n",
      "\n",
      "                                          Base  \\\n",
      "0                   FITA DUREX TRANSP 12X50 3M   \n",
      "1                   BROCA VIDEA SDS PLUS IRWIN   \n",
      "2              RATOEIRA GAIOLA CMOLA CHACONFER   \n",
      "3              RATOEIRA GAIOLA CMOLA CHACONFER   \n",
      "4              RATOEIRA GAIOLA CMOLA CHACONFER   \n",
      "...                                        ...   \n",
      "4096                    BROCA IRWIN WIDEA PLUS   \n",
      "4097         PINO MACHO REDY 2P 10A POTE CORES   \n",
      "4098       FURAD BD IMPACTO 38 220V TM500 560W   \n",
      "4099  TUBO CORR PLASTIK ESGOTO 100MM BARRA 6MT   \n",
      "4100   TUBO CORR PLASTIK ESGOTO 50MM BARRA 6MT   \n",
      "\n",
      "                                     Variante GTIN_Válido  \n",
      "0                                         NaN        True  \n",
      "1          BROCA VIDEA SDS PLUS 100X160 IRWIN        True  \n",
      "2     RATOEIRA GAIOLA CMOLA PEQUENA CHACONFER        True  \n",
      "3       RATOEIRA GAIOLA CMOLA MEDIA CHACONFER        True  \n",
      "4      RATOEIRA GAIOLA CMOLA GRANDE CHACONFER        True  \n",
      "...                                       ...         ...  \n",
      "4096                                  100X210       False  \n",
      "4097                                      NaN       False  \n",
      "4098                                      NaN       False  \n",
      "4099                                      NaN       False  \n",
      "4100                                      NaN       False  \n",
      "\n",
      "[4101 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14415/1561190686.py:34: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filtrado = df_validos.groupby('Código de Barras', group_keys=False).apply(escolher_prioritario)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from env import fornecedores_web_scraping\n",
    "\n",
    "df = pd.read_excel(\"final.xlsx\")\n",
    "\n",
    "\n",
    "def gtin(codigo):\n",
    "    return codigo.isdigit() and len(codigo) in [8, 12, 13, 14]\n",
    "\n",
    "\n",
    "df[\"GTIN_Válido\"] = df[\"Código de Barras\"].astype(str).apply(gtin)\n",
    "\n",
    "df_validos = df[df[\"GTIN_Válido\"]].copy()\n",
    "\n",
    "\n",
    "def escolher_prioritario(grupo):\n",
    "    if len(grupo) == 1:\n",
    "        return grupo\n",
    "    fornecedores = grupo[\"Fornecedor\"].tolist()\n",
    "\n",
    "    if any(f in fornecedores_web_scraping for f in fornecedores):\n",
    "        return grupo[grupo[\"Fornecedor\"].isin(fornecedores_web_scraping)].head(1)\n",
    "\n",
    "    return grupo.head(1)\n",
    "\n",
    "\n",
    "df_filtrado = df_validos.groupby(\"Código de Barras\", group_keys=False).apply(\n",
    "    escolher_prioritario\n",
    ")\n",
    "\n",
    "df_final = pd.concat([df_filtrado, df[~df[\"GTIN_Válido\"]]], ignore_index=True)\n",
    "\n",
    "df_final = df_final.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
