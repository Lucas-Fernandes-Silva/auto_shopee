{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4edf798",
   "metadata": {},
   "source": [
    "#Criar um script que faça:  \n",
    "#Pegue as nfe em xml do email  \n",
    "#Extrai os dados necessarios   \n",
    "#Tratar dados   \n",
    "#Remover materiais pesado E outras notas \n",
    "-TABUAS CABOQUINHO  \n",
    "-CIMENTRO VOTORAN  \n",
    "-Magalu   \n",
    "\n",
    "#Aplicador formula de taxas  \n",
    "#Inserir no template dos marketplaces\n",
    "\n",
    "Ultilizar api do bling para cadastro de itens   (quando tiver)\n",
    "\n",
    "\n",
    "Mercado LIVRE:50% do valor do produto (para produtos até R$ 12,50), R$ 6,25 (entre R$ 12,50 e R$ 29), R$ 6,50 (entre R$ 29 e R$ 50) e R$ 6,75 (entre R$ 50 e R$ 79)\n",
    "\n",
    "Comissão de Categoria Construção 12%\n",
    "\n",
    "\n",
    "SHOPE taxa de transação é sobre o total do produto então é 2% de taxa e 18 de comissão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fbee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from imap_tools import MailBox, AND\n",
    "from env import pwd, user\n",
    "from datetime import date, datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"notas/nfes/\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "with MailBox(\"imap.gmail.com\").login(user, pwd, initial_folder=\"INBOX\", ) as mailbox:\n",
    "    list_mail = mailbox.fetch(criteria=AND(date=date.today())\n",
    "\n",
    "    )\n",
    "    for email in list_mail:\n",
    "        for anexo in email.attachments:\n",
    "            if  anexo.filename.lower().endswith(\".xml\"):\n",
    "                file_path = os.path.join(save_folder, anexo.filename)\n",
    "                if not os.path.exists(file_path):   \n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        f.write(anexo.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os XMLs em pastas por Emitente e extrai os produtos para um Excel\n",
    "\n",
    "pasta_origem = \"notas/nfes\"\n",
    "todos_produtos = []\n",
    "\n",
    "\n",
    "def extrai_dados(caminho_arquivo):\n",
    "    produtos = []\n",
    "    tree = ET.parse(caminho_arquivo)\n",
    "    root = tree.getroot()\n",
    "    ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "    data_str = root.find(\".//ns:ide/ns:dhEmi\", ns).text\n",
    "    data_emissao = datetime.fromisoformat(data_str)\n",
    "\n",
    "    \n",
    "    natOp = root.find(\".//ns:ide/ns:natOp\", ns)\n",
    "    if natOp is not None and natOp.text.strip().upper() == 'BONIFICACAO, DOACAO OU BRINDE':\n",
    "        return [] \n",
    "    \n",
    "    for det in root.findall(\".//ns:det\", ns):   \n",
    "        produto = {}\n",
    "        temp_codigo = det.find(\"./ns:prod/ns:cProd\", ns).text\n",
    "        if not \"-\" in temp_codigo:\n",
    "            produto ['Codigo Produto'] = temp_codigo\n",
    "        produto ['Descrição'] = det.find(\"./ns:prod/ns:xProd\", ns).text\n",
    "        produto ['Valor_unitário'] = det.find(\"./ns:prod/ns:vUnCom\", ns).text\n",
    "        produto ['Código de Barras'] = det.find(\"./ns:prod/ns:cEAN\", ns).text \n",
    "        produto ['Sku'] = produto['Código de Barras']\n",
    "        if produto['Sku'] == 'SEM GTIN':\n",
    "            produto['Sku'] = produto['Descrição']\n",
    "        produto ['Fornecedor'] = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "        produto ['Data Emissão'] = data_emissao\n",
    "\n",
    "        produtos.append(produto)\n",
    "    return produtos\n",
    "\n",
    "\n",
    "# Percorre todos os arquivos da pasta\n",
    "for arquivo in os.listdir(pasta_origem):\n",
    "    if arquivo.lower().endswith(\".xml\"):\n",
    "        caminho_arquivo = os.path.join(pasta_origem, arquivo)\n",
    "\n",
    "        try:\n",
    "            # Abre e parseia o XML\n",
    "            tree = ET.parse(caminho_arquivo)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Define namespace\n",
    "            ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "\n",
    "            # Busca o CNPJ do emitente\n",
    "            cnpj_emitente = root.find(\".//ns:emit/ns:CNPJ\", ns)\n",
    "            cnpj_emitente\n",
    "            if cnpj_emitente is None:\n",
    "                print(f\"⚠️ CNPJ não encontrado em {arquivo}\")\n",
    "                continue\n",
    "\n",
    "            cnpj_emitente = cnpj_emitente.text\n",
    "\n",
    "            produtos = extrai_dados(caminho_arquivo)\n",
    "            todos_produtos.extend(produtos)              \n",
    "\n",
    "\n",
    "            emitente = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "            \n",
    "            pasta_destino = os.path.join(\"notas/\")\n",
    "\n",
    "            # Cria a pasta se não existir\n",
    "            os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "            # Copia o arquivo para a pasta\n",
    "            shutil.copy(caminho_arquivo, pasta_destino)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" {arquivo}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "fornecedores_pesados = [\n",
    "    'IND E COM DE TUBOS E CONEXOES FORT.COM',\n",
    "    'VOTORANTIM CIMENTOS SA',\n",
    "    'CABOQUINHO MATERIAIS PARA CONSTRUCAO'\n",
    "]\n",
    "\n",
    "\n",
    "produtos = pd.DataFrame(todos_produtos)\n",
    "produtos = produtos[~produtos['Fornecedor'].isin(fornecedores_pesados)]\n",
    "produtos = produtos.sort_values(by=\"Data Emissão\", ascending=False)\n",
    "\n",
    "produtos = produtos.drop_duplicates(subset='Codigo Produto', keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos['Fornecedor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f384208",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d981c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONEXÕES ÁGUA\n",
      "name 'codigo_barras' is not defined\n"
     ]
    }
   ],
   "source": [
    "read = pd.read_excel('upseller_template.xlsx')\n",
    "produtos = read[-1:]\n",
    "\n",
    "\n",
    "for  index, produto in produtos.iterrows():\n",
    "    # fornecedor = produto['Fornecedor']\n",
    "    # codigo_produto = produto['Codigo Produto']\n",
    "    # descricao = produto['Descrição']\n",
    "    try:\n",
    "    #     if fornecedor == 'CONSTRUDIGI DISTRIBUIDORA DE MATERIAIS PARA CONSTRUCAO LTDA':   \n",
    "    #         url = f'https://www.construdigi.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     elif fornecedor == 'M.S.B. COMERCIO DE MATERIAIS PARA CONSTRUCAO':\n",
    "    #         url = f'https://msbitaqua.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     elif fornecedor == \"CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU\":\n",
    "    #         url = f'https://www.construja.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     else:\n",
    "    #         print('Indisponivel')\n",
    "    #         continue\n",
    "        \n",
    "        url = 'https://construja.com.br/produto/101223/estrela-tapa-furo-ll-20mm'\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        script = soup.find(\"script\", type=\"application/json\")\n",
    "        data = json.loads(script.string) if script else {}\n",
    "       \n",
    "        extrai = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"produto\", {})\n",
    "        comprimento = extrai.get(\"comprimento\")\n",
    "\n",
    "        url_img = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"seo\", {}).get(\"imageUrl\", 'Não disponivel')\n",
    "        marca = next((p.get(\"desc\") for p in extrai.get(\"dimensoes\", []) if p.get(\"label\") == \"MARCA\"), \"Não disponível\")\n",
    "        categoria = next((p.get(\"desc\") for p in extrai.get(\"dimensoes\", []) if p.get(\"label\") == \"SUB CATEGORIA\"), \"Não disponível\")\n",
    "        print(categoria)\n",
    "        peso = extrai.get(\"pesoBruto\", \"Não disponível\")\n",
    "        if codigo_barras == 'SEM GTIN':\n",
    "            codigo_barras = extrai.get(\"codBarra\", \"SEM GTIN\")\n",
    "        produtos.at[index, 'Código de Barras'] = codigo_barras\n",
    "        produtos.at[index, 'Peso'] = peso\n",
    "        produtos.at[index, \"Marca\"] = marca\n",
    "        produtos.at[index, 'Url Imagem'] = url_img\n",
    "        \n",
    "        print(produto['Descrição'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from env import fornecedores_noweb_scapping\n",
    "\n",
    "# === 1. Carregar o arquivo ===\n",
    "df = pd.read_excel('produtos.xlsx')\n",
    "\n",
    "# === 2. Função para limpar e normalizar texto ===\n",
    "def limpar_texto(txt):\n",
    "    if not isinstance(txt, str):\n",
    "\n",
    "        return \"\"\n",
    "    # Remove acentos\n",
    "    txt = unicodedata.normalize('NFD', txt)\n",
    "    txt = txt.encode('ascii', 'ignore').decode('utf-8')\n",
    "    # Converte para maiúsculas\n",
    "    txt = txt.upper()\n",
    "    # Remove caracteres especiais\n",
    "    txt = re.sub(r'[^A-Z0-9 ]', '', txt)\n",
    "    # Remove espaços duplicados\n",
    "    txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "    return txt\n",
    "\n",
    "\n",
    "# === 3. Lista de marcas fixas (forçadas a fazer parte da análise) ===\n",
    "marcas_adicionais = [\n",
    "    'SHIVA','BRASCOLA','FERTAK','NATICON','NOBRE','ADELBRAS','STA MARINA','FIRMEZA','OLIPLAS','STAM', 'R.C.A','CORONA','TOP FIO',\n",
    "    'MAKITA','REXON','SOPRANO','FAST LUB','ACQUA','KIAN','SOUDAL','DEPLAST','TATU','GRENDHA', 'PANASONIC','PAULICEIA','MORIA',\n",
    "    'ALLTAPE','PLASTILIT','TITANIUM','FERRARI','NEGREIRA','RADIAL','BLUMENAU','J.F METAIS','ART METAIS','LONAX', 'GHEL PLUS',\n",
    "    'CHEMICOLOR','SANY','PROAQUA','BICROM','WAGO','TECHNA','METASUL','GARAPEIRA','ROCO','PRO FOAM','DURACELL','POLIBEL','AGELUX',\n",
    "    'REMOX','RORATO','WAVES','LEGRAND','PAPAIZ','AGELUZ','IMPERIAL','HYDRA','KITUBO','NETTE','SANLIMP', 'EMA METAIS','M&M'\n",
    "    'BEARS','ADTEX','GALO','PEGAFORTE','EMAVE','ELGIN','LUCONI','VEGA','MUNDIAL','DELTA', 'COBRECOM','PLASTBIG','FERE','SATA',\n",
    "    'ALUMBRA', 'FIOLUX','PACETTA','ITAMBE','PEXCEL','EMAVA','KADESH','IBERE','GOLD','PERLEX','IMA','SAFETY','PIAL','PLASTIK',\n",
    "    'OUROLUX', 'LED BEE','BELZER','PROTEG','NASTRO','FJ FERR', 'SAO RAFAEL', 'STILLUS','FLASH LIMP', 'ZUMPLAST','REDY','PRIMETECH',\n",
    "    'SECALUX', 'PLASTIC','SUPER BONDER', 'ARTPLAS','FABER CASTELL','GUARANI','DEWALT','ALUREM','PERFIX ','STELL','FERROX','USAF',\n",
    "    'INJET','CMK','BEARS','MINASUL','DEGOMASTER','SIENA'\n",
    "]\n",
    "marcas_adicionais = [limpar_texto(m) for m in marcas_adicionais]\n",
    "\n",
    "\n",
    "# === 4. Dicionário de sinônimos / variações ===\n",
    "mapa_variacoes = {\n",
    "    'TRAMONTINA': ['TRAMON', 'TRAMONTINA', 'TRAMONTINA ELE', 'TRAMONTINA GARI', 'TRAMONTINA MULT', 'TRAM'],\n",
    "    'JOMARCA': ['JOMARCA', 'JOMARC', 'JOMARCA JMC', 'JMC'],\n",
    "    'NEW FIX': ['NEW FIX', 'NEWFIX', 'NEW-FIX', 'NEW F','PARAF CHIPBOARD CHATA PHS','PARAF SEX.ROS.SOBERBA'],\n",
    "    'NOVA': ['NOVA TINTAS', 'NOVA'],\n",
    "    'DRYKO': ['DRYKO', 'DRYKOPRIMER'],\n",
    "    'SIKA': ['SIKATOP', 'SIKA'],\n",
    "    'BRASFORT': ['BRASF', 'BRASFORT'],\n",
    "    'ILUMI': ['ILUM', 'ILUMI'],\n",
    "    'DENVER': ['DENVER','DENVERIMPER', 'DENVERLAJE','DENVERTEC','DENVERCRILL', 'DENVERFITA','DENVERFIX'],\n",
    "    'THOMPSOM': ['THOMPSOM', 'THOMP'],\n",
    "    'PEGAFORTE': ['PEGAFORTE', 'PEGA FORTE'],\n",
    "    'CALHA FORTE': ['CALHA FORTE', 'CALHA FORT'],\n",
    "    'VEDACIT': ['VEDACIT', 'BIANCO'],\n",
    "    'LORENZETTI': ['LOREN','LORENZETTI','ORIG.L&C D','.PMR D.','.L&C '],\n",
    "    'KADESH': ['BOT FLEX ELASTICO PRETA BI']\n",
    "}\n",
    "\n",
    "\n",
    "# === 5. Montar lista final de marcas conhecidas ===\n",
    "marcas_planilha = df['Marca'].dropna().unique().tolist()\n",
    "marcas_planilha.remove('5+')\n",
    "marcas_planilha = [limpar_texto(m) for m in marcas_planilha if isinstance(m, str) and m.strip()]\n",
    "\n",
    "# Combinar todas\n",
    "marcas = list(set(marcas_planilha + marcas_adicionais))\n",
    "\n",
    "# Adicionar também as variações do mapa\n",
    "for marca_principal, variacoes in mapa_variacoes.items():\n",
    "    marcas.append(marca_principal)\n",
    "    marcas.extend([limpar_texto(v) for v in variacoes])\n",
    "\n",
    "marcas = list(set(marcas))\n",
    "\n",
    "\n",
    "# === 7. Função para detectar marca na descrição ===\n",
    "def detectar_marca(descricao):\n",
    "    desc_limpa = limpar_texto(descricao)\n",
    "\n",
    "    # Verifica variações conhecidas primeiro\n",
    "    for marca_padrao, variacoes in mapa_variacoes.items():\n",
    "        for v in variacoes:\n",
    "            if limpar_texto(v) in desc_limpa:\n",
    "                return marca_padrao\n",
    "\n",
    "    # Caso não encontre nas variações, busca direta na lista geral\n",
    "    for marca in marcas:\n",
    "        if marca and marca in desc_limpa:\n",
    "            return marca\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "df_filtrado = df.copy()\n",
    "\n",
    "# === 8. Detectar e preencher marcas ausentes ===\n",
    "df_filtrado['Marca Detectada'] = df_filtrado['Descrição'].apply(detectar_marca)\n",
    "\n",
    "# Preenche apenas onde está vazio\n",
    "df_filtrado['Marca'] = df_filtrado['Marca'].fillna(df_filtrado['Marca Detectada'])\n",
    "\n",
    "df_filtrado['Marca'] = df_filtrado['Marca'].fillna('GENÉRICO')\n",
    "# Atualiza no dataframe principal\n",
    "df.update(df_filtrado)\n",
    "\n",
    "\n",
    "# === 9. Salvar resultado ===\n",
    "df.to_excel('produtos_com_marcas.xlsx', index=False)\n",
    "\n",
    "# === 10. Relatório simples ===\n",
    "print(\"✅ Processamento concluído!\")\n",
    "print(f\"Total de produtos analisados: {len(df_filtrado)}\")\n",
    "print(f\"Marcas detectadas automaticamente: {df_filtrado['Marca Detectada'].notna().sum()}\")\n",
    "\n",
    "# Top 10 marcas mais detectadas\n",
    "print(\"\\nTop marcas detectadas:\")\n",
    "print(df_filtrado['Marca Detectada'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f84477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1136/1252498151.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: extrair_base_variacao(g.copy()))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "df = pd.read_excel('pai_filho_variantes.xlsx')\n",
    "\n",
    "# --- Função para normalizar ---\n",
    "def normalizar(texto):\n",
    "    texto = str(texto).lower().strip()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    return texto\n",
    "\n",
    "df[\"chave_norm\"] = df[\"chave\"].apply(normalizar)\n",
    "\n",
    "# --- Função para encontrar a base e variação dentro de um grupo ---\n",
    "def extrair_base_variacao(grupo_df):\n",
    "    textos = grupo_df[\"chave_norm\"].tolist()\n",
    "    palavras = [set(t.split()) for t in textos]\n",
    "\n",
    "    comuns = set.intersection(*palavras) \n",
    "    bases, variacoes = [], []\n",
    "    for texto in textos:\n",
    "        palavras_texto = texto.split()\n",
    "        variacao = [p for p in palavras_texto if p not in comuns]\n",
    "        base = [p for p in palavras_texto if p in comuns]\n",
    "        bases.append(\" \".join(base))\n",
    "        variacoes.append(\" \".join(variacao))\n",
    "    \n",
    "    grupo_df[\"base\"] = bases\n",
    "    grupo_df[\"variacao\"] = variacoes\n",
    "    return grupo_df\n",
    "\n",
    "# --- Aplica por grupo ---\n",
    "df_resultado = (\n",
    "    df.groupby(\"ID_Variacao\", group_keys=False)\n",
    "      .apply(lambda g: extrair_base_variacao(g.copy()))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_resultado.to_excel('base_nome.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
