{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4edf798",
   "metadata": {},
   "source": [
    "#Criar um script que faça:  \n",
    "#Pegue as nfe em xml do email  \n",
    "#Extrai os dados necessarios   \n",
    "#Tratar dados   \n",
    "#Remover materiais pesado E outras notas \n",
    "-TABUAS CABOQUINHO  \n",
    "-CIMENTRO VOTORAN  \n",
    "-Magalu   \n",
    "\n",
    "#Aplicador formula de taxas  \n",
    "#Inserir no template dos marketplaces\n",
    "\n",
    "Ultilizar api do bling para cadastro de itens   (quando tiver)\n",
    "\n",
    "\n",
    "Mercado LIVRE:50% do valor do produto (para produtos até R$ 12,50), R$ 6,25 (entre R$ 12,50 e R$ 29), R$ 6,50 (entre R$ 29 e R$ 50) e R$ 6,75 (entre R$ 50 e R$ 79)\n",
    "\n",
    "Comissão de Categoria Construção 12%\n",
    "\n",
    "\n",
    "SHOPE taxa de transação é sobre o total do produto então é 2% de taxa e 18 de comissão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from imap_tools import MailBox, AND\n",
    "from env import pwd, user\n",
    "from datetime import date, datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"notas/nfes/\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "with MailBox(\"imap.gmail.com\").login(user, pwd, initial_folder=\"INBOX\", ) as mailbox:\n",
    "    list_mail = mailbox.fetch(criteria=AND(date=date.today())\n",
    "\n",
    "    )\n",
    "    for email in list_mail:\n",
    "        for anexo in email.attachments:\n",
    "            if  anexo.filename.lower().endswith(\".xml\"):\n",
    "                file_path = os.path.join(save_folder, anexo.filename)\n",
    "                if not os.path.exists(file_path):   \n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        f.write(anexo.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os XMLs em pastas por Emitente e extrai os produtos para um Excel\n",
    "\n",
    "pasta_origem = \"notas/nfes\"\n",
    "todos_produtos = []\n",
    "\n",
    "\n",
    "def extrai_dados(caminho_arquivo):\n",
    "    produtos = []\n",
    "    tree = ET.parse(caminho_arquivo)\n",
    "    root = tree.getroot()\n",
    "    ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "    data_str = root.find(\".//ns:ide/ns:dhEmi\", ns).text\n",
    "    data_emissao = datetime.fromisoformat(data_str)\n",
    "\n",
    "    \n",
    "    natOp = root.find(\".//ns:ide/ns:natOp\", ns)\n",
    "    if natOp is not None and natOp.text.strip().upper() == 'BONIFICACAO, DOACAO OU BRINDE':\n",
    "        return [] \n",
    "    \n",
    "    for det in root.findall(\".//ns:det\", ns):   \n",
    "        produto = {}\n",
    "        temp_codigo = det.find(\"./ns:prod/ns:cProd\", ns).text\n",
    "        if not \"-\" in temp_codigo:\n",
    "            produto ['Codigo Produto'] = temp_codigo\n",
    "        produto ['Descrição'] = det.find(\"./ns:prod/ns:xProd\", ns).text\n",
    "        produto ['Valor_unitário'] = det.find(\"./ns:prod/ns:vUnCom\", ns).text\n",
    "        produto ['Código de Barras'] = det.find(\"./ns:prod/ns:cEAN\", ns).text \n",
    "        produto ['Sku'] = produto['Código de Barras']\n",
    "        if produto['Sku'] == 'SEM GTIN':\n",
    "            produto['Sku'] = produto['Descrição']\n",
    "        produto ['Fornecedor'] = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "        produto ['Data Emissão'] = data_emissao\n",
    "\n",
    "        produtos.append(produto)\n",
    "    return produtos\n",
    "\n",
    "\n",
    "# Percorre todos os arquivos da pasta\n",
    "for arquivo in os.listdir(pasta_origem):\n",
    "    if arquivo.lower().endswith(\".xml\"):\n",
    "        caminho_arquivo = os.path.join(pasta_origem, arquivo)\n",
    "\n",
    "        try:\n",
    "            # Abre e parseia o XML\n",
    "            tree = ET.parse(caminho_arquivo)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Define namespace\n",
    "            ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "\n",
    "            # Busca o CNPJ do emitente\n",
    "            cnpj_emitente = root.find(\".//ns:emit/ns:CNPJ\", ns)\n",
    "            cnpj_emitente\n",
    "            if cnpj_emitente is None:\n",
    "                print(f\"⚠️ CNPJ não encontrado em {arquivo}\")\n",
    "                continue\n",
    "\n",
    "            cnpj_emitente = cnpj_emitente.text\n",
    "\n",
    "            produtos = extrai_dados(caminho_arquivo)\n",
    "            todos_produtos.extend(produtos)              \n",
    "\n",
    "\n",
    "            emitente = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "            \n",
    "            pasta_destino = os.path.join(\"notas/\")\n",
    "\n",
    "            # Cria a pasta se não existir\n",
    "            os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "            # Copia o arquivo para a pasta\n",
    "            shutil.copy(caminho_arquivo, pasta_destino)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" {arquivo}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "fornecedores_pesados = [\n",
    "    'IND E COM DE TUBOS E CONEXOES FORT.COM',\n",
    "    'VOTORANTIM CIMENTOS SA',\n",
    "    'CABOQUINHO MATERIAIS PARA CONSTRUCAO'\n",
    "]\n",
    "\n",
    "\n",
    "produtos = pd.DataFrame(todos_produtos)\n",
    "produtos = produtos[~produtos['Fornecedor'].isin(fornecedores_pesados)]\n",
    "produtos = produtos.sort_values(by=\"Data Emissão\", ascending=False)\n",
    "\n",
    "produtos = produtos.drop_duplicates(subset='Codigo Produto', keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos['Fornecedor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f384208",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d981c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_excel('upseller_template.xlsx')\n",
    "produtos = read[-1:]\n",
    "\n",
    "\n",
    "for  index, produto in produtos.iterrows():\n",
    "    # fornecedor = produto['Fornecedor']\n",
    "    # codigo_produto = produto['Codigo Produto']\n",
    "    # descricao = produto['Descrição']\n",
    "    try:\n",
    "    #     if fornecedor == 'CONSTRUDIGI DISTRIBUIDORA DE MATERIAIS PARA CONSTRUCAO LTDA':   \n",
    "    #         url = f'https://www.construdigi.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     elif fornecedor == 'M.S.B. COMERCIO DE MATERIAIS PARA CONSTRUCAO':\n",
    "    #         url = f'https://msbitaqua.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     elif fornecedor == \"CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU\":\n",
    "    #         url = f'https://www.construja.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     else:\n",
    "    #         print('Indisponivel')\n",
    "    #         continue\n",
    "        \n",
    "        url = 'https://construja.com.br/produto/101223/estrela-tapa-furo-ll-20mm'\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        script = soup.find(\"script\", type=\"application/json\")\n",
    "        data = json.loads(script.string) if script else {}\n",
    "       \n",
    "        extrai = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"produto\", {})\n",
    "        comprimento = extrai.get(\"comprimento\")\n",
    "\n",
    "        url_img = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"seo\", {}).get(\"imageUrl\", 'Não disponivel')\n",
    "        marca = next((p.get(\"desc\") for p in extrai.get(\"dimensoes\", []) if p.get(\"label\") == \"MARCA\"), \"Não disponível\")\n",
    "        categoria = next((p.get(\"desc\") for p in extrai.get(\"dimensoes\", []) if p.get(\"label\") == \"SUB CATEGORIA\"), \"Não disponível\")\n",
    "        print(categoria)\n",
    "        peso = extrai.get(\"pesoBruto\", \"Não disponível\")\n",
    "        if codigo_barras == 'SEM GTIN':\n",
    "            codigo_barras = extrai.get(\"codBarra\", \"SEM GTIN\")\n",
    "        produtos.at[index, 'Código de Barras'] = codigo_barras\n",
    "        produtos.at[index, 'Peso'] = peso\n",
    "        produtos.at[index, \"Marca\"] = marca\n",
    "        produtos.at[index, 'Url Imagem'] = url_img\n",
    "        \n",
    "        print(produto['Descrição'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from env import fornecedores_noweb_scapping\n",
    "\n",
    "# === 1. Carregar o arquivo ===\n",
    "df = pd.read_excel('produtos.xlsx')\n",
    "\n",
    "# === 2. Função para limpar e normalizar texto ===\n",
    "def limpar_texto(txt):\n",
    "    if not isinstance(txt, str):\n",
    "\n",
    "        return \"\"\n",
    "    # Remove acentos\n",
    "    txt = unicodedata.normalize('NFD', txt)\n",
    "    txt = txt.encode('ascii', 'ignore').decode('utf-8')\n",
    "    # Converte para maiúsculas\n",
    "    txt = txt.upper()\n",
    "    # Remove caracteres especiais\n",
    "    txt = re.sub(r'[^A-Z0-9 ]', '', txt)\n",
    "    # Remove espaços duplicados\n",
    "    txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "    return txt\n",
    "\n",
    "\n",
    "# === 3. Lista de marcas fixas (forçadas a fazer parte da análise) ===\n",
    "marcas_adicionais = [\n",
    "    'SHIVA','BRASCOLA','FERTAK','NATICON','NOBRE','ADELBRAS','STA MARINA','FIRMEZA','OLIPLAS','STAM', 'R.C.A','CORONA','TOP FIO',\n",
    "    'MAKITA','REXON','SOPRANO','FAST LUB','ACQUA','KIAN','SOUDAL','DEPLAST','TATU','GRENDHA', 'PANASONIC','PAULICEIA','MORIA',\n",
    "    'ALLTAPE','PLASTILIT','TITANIUM','FERRARI','NEGREIRA','RADIAL','BLUMENAU','J.F METAIS','ART METAIS','LONAX', 'GHEL PLUS',\n",
    "    'CHEMICOLOR','SANY','PROAQUA','BICROM','WAGO','TECHNA','METASUL','GARAPEIRA','ROCO','PRO FOAM','DURACELL','POLIBEL','AGELUX',\n",
    "    'REMOX','RORATO','WAVES','LEGRAND','PAPAIZ','AGELUZ','IMPERIAL','HYDRA','KITUBO','NETTE','SANLIMP', 'EMA METAIS','M&M'\n",
    "    'BEARS','ADTEX','GALO','PEGAFORTE','EMAVE','ELGIN','LUCONI','VEGA','MUNDIAL','DELTA', 'COBRECOM','PLASTBIG','FERE','SATA',\n",
    "    'ALUMBRA', 'FIOLUX','PACETTA','ITAMBE','PEXCEL','EMAVA','KADESH','IBERE','GOLD','PERLEX','IMA','SAFETY','PIAL','PLASTIK',\n",
    "    'OUROLUX', 'LED BEE','BELZER','PROTEG','NASTRO','FJ FERR', 'SAO RAFAEL', 'STILLUS','FLASH LIMP', 'ZUMPLAST','REDY','PRIMETECH',\n",
    "    'SECALUX', 'PLASTIC','SUPER BONDER', 'ARTPLAS','FABER CASTELL','GUARANI','DEWALT','ALUREM','PERFIX ','STELL','FERROX','USAF',\n",
    "    'INJET','CMK','BEARS','MINASUL','DEGOMASTER','SIENA'\n",
    "]\n",
    "marcas_adicionais = [limpar_texto(m) for m in marcas_adicionais]\n",
    "\n",
    "\n",
    "# === 4. Dicionário de sinônimos / variações ===\n",
    "mapa_variacoes = {\n",
    "    'TRAMONTINA': ['TRAMON', 'TRAMONTINA', 'TRAMONTINA ELE', 'TRAMONTINA GARI', 'TRAMONTINA MULT', 'TRAM'],\n",
    "    'JOMARCA': ['JOMARCA', 'JOMARC', 'JOMARCA JMC', 'JMC'],\n",
    "    'NEW FIX': ['NEW FIX', 'NEWFIX', 'NEW-FIX', 'NEW F','PARAF CHIPBOARD CHATA PHS','PARAF SEX.ROS.SOBERBA'],\n",
    "    'NOVA': ['NOVA TINTAS', 'NOVA'],\n",
    "    'DRYKO': ['DRYKO', 'DRYKOPRIMER'],\n",
    "    'SIKA': ['SIKATOP', 'SIKA'],\n",
    "    'BRASFORT': ['BRASF', 'BRASFORT'],\n",
    "    'ILUMI': ['ILUM', 'ILUMI'],\n",
    "    'DENVER': ['DENVER','DENVERIMPER', 'DENVERLAJE','DENVERTEC','DENVERCRILL', 'DENVERFITA','DENVERFIX'],\n",
    "    'THOMPSOM': ['THOMPSOM', 'THOMP'],\n",
    "    'PEGAFORTE': ['PEGAFORTE', 'PEGA FORTE'],\n",
    "    'CALHA FORTE': ['CALHA FORTE', 'CALHA FORT'],\n",
    "    'VEDACIT': ['VEDACIT', 'BIANCO'],\n",
    "    'LORENZETTI': ['LOREN','LORENZETTI','ORIG.L&C D','.PMR D.','.L&C '],\n",
    "    'KADESH': ['BOT FLEX ELASTICO PRETA BI']\n",
    "}\n",
    "\n",
    "\n",
    "# === 5. Montar lista final de marcas conhecidas ===\n",
    "marcas_planilha = df['Marca'].dropna().unique().tolist()\n",
    "marcas_planilha.remove('5+')\n",
    "marcas_planilha = [limpar_texto(m) for m in marcas_planilha if isinstance(m, str) and m.strip()]\n",
    "\n",
    "# Combinar todas\n",
    "marcas = list(set(marcas_planilha + marcas_adicionais))\n",
    "\n",
    "# Adicionar também as variações do mapa\n",
    "for marca_principal, variacoes in mapa_variacoes.items():\n",
    "    marcas.append(marca_principal)\n",
    "    marcas.extend([limpar_texto(v) for v in variacoes])\n",
    "\n",
    "marcas = list(set(marcas))\n",
    "\n",
    "\n",
    "# === 7. Função para detectar marca na descrição ===\n",
    "def detectar_marca(descricao):\n",
    "    desc_limpa = limpar_texto(descricao)\n",
    "\n",
    "    # Verifica variações conhecidas primeiro\n",
    "    for marca_padrao, variacoes in mapa_variacoes.items():\n",
    "        for v in variacoes:\n",
    "            if limpar_texto(v) in desc_limpa:\n",
    "                return marca_padrao\n",
    "\n",
    "    # Caso não encontre nas variações, busca direta na lista geral\n",
    "    for marca in marcas:\n",
    "        if marca and marca in desc_limpa:\n",
    "            return marca\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "df_filtrado = df.copy()\n",
    "\n",
    "# === 8. Detectar e preencher marcas ausentes ===\n",
    "df_filtrado['Marca Detectada'] = df_filtrado['Descrição'].apply(detectar_marca)\n",
    "\n",
    "# Preenche apenas onde está vazio\n",
    "df_filtrado['Marca'] = df_filtrado['Marca'].fillna(df_filtrado['Marca Detectada'])\n",
    "\n",
    "df_filtrado['Marca'] = df_filtrado['Marca'].fillna('GENÉRICO')\n",
    "# Atualiza no dataframe principal\n",
    "df.update(df_filtrado)\n",
    "\n",
    "\n",
    "# === 9. Salvar resultado ===\n",
    "df.to_excel('produtos_com_marcas.xlsx', index=False)\n",
    "\n",
    "# === 10. Relatório simples ===\n",
    "print(\"✅ Processamento concluído!\")\n",
    "print(f\"Total de produtos analisados: {len(df_filtrado)}\")\n",
    "print(f\"Marcas detectadas automaticamente: {df_filtrado['Marca Detectada'].notna().sum()}\")\n",
    "\n",
    "# Top 10 marcas mais detectadas\n",
    "print(\"\\nTop marcas detectadas:\")\n",
    "print(df_filtrado['Marca Detectada'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "df = pd.read_excel('pai_filho_variantes.xlsx')\n",
    "\n",
    "# --- Função para normalizar ---\n",
    "def normalizar(texto):\n",
    "    texto = str(texto).lower().strip()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    return texto\n",
    "\n",
    "df[\"chave_norm\"] = df[\"chave\"].apply(normalizar)\n",
    "\n",
    "# --- Função para encontrar a base e variação dentro de um grupo ---\n",
    "def extrair_base_variacao(grupo_df):\n",
    "    textos = grupo_df[\"chave_norm\"].tolist()\n",
    "    palavras = [set(t.split()) for t in textos]\n",
    "\n",
    "    comuns = set.intersection(*palavras) \n",
    "    bases, variacoes = [], []\n",
    "    for texto in textos:\n",
    "        palavras_texto = texto.split()\n",
    "        variacao = [p for p in palavras_texto if p not in comuns]\n",
    "        base = [p for p in palavras_texto if p in comuns]\n",
    "        bases.append(\" \".join(base))\n",
    "        variacoes.append(\" \".join(variacao))\n",
    "    \n",
    "    grupo_df[\"base\"] = bases\n",
    "    grupo_df[\"variacao\"] = variacoes\n",
    "    return grupo_df\n",
    "\n",
    "# --- Aplica por grupo ---\n",
    "df_resultado = (\n",
    "    df.groupby(\"ID_Variacao\", group_keys=False)\n",
    "      .apply(lambda g: extrair_base_variacao(g.copy()))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_resultado.to_excel('base_nome.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12ab5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Agrupando variações...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1403.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 Gerando colunas base e variante...\n",
      "   ID_Variacao                                              Chave\n",
      "0            1         FITA CREPE 48X50 USO GERAL MASK FITA CREPE\n",
      "1            1         FITA CREPE 24X50 USO GERAL MASK FITA CREPE\n",
      "2            2   VALV RETENCAO ESG 100/75 ESTRELA CONEXOES ESGOTO\n",
      "3            2    VALV RETENCAO ESG 50/40 ESTRELA CONEXOES ESGOTO\n",
      "4            3  VELA FILTRO GRAVIDADE V/C CRISTALINA DIVERSOS ...\n",
      "5            4  CHAVE PHILLIPS CRV TOCO C/PI 1/4X11/2 FAMASTIL...\n",
      "6            5  CHAVE FENDA TOCO CRV C/PI 3/16X11/2 FOX/FAMAST...\n",
      "7            6  LAMP LED ALTA POT 30W-2400LM 6500K GALAXY LAMP...\n",
      "8            6  LAMP LED ALTA POT 40W-3200LM 6500K GALAXY LAMP...\n",
      "9            6  LAMP LED ALTA POT 50W-4000LM 6500K GALAXY LAMP...\n",
      "10           6  LAMP LED ALTA POT 20W-1600LM 6500K GALAXY LAMP...\n",
      "11           7  LAMP LED ALTA POT 50W-4000LM 6500K FOXLUX LAMP...\n",
      "12           8  LAMP LED ALTA POT 50W-4000LM 6500K AVANT LAMPADAS\n",
      "13           9         CX DESC S/E 6/9L BR ALUMASA CAIXA DESCARGA\n",
      "14          10  RECEPTACULO E27 1451 THOMPSON LUMINARIAS SUPOR...\n",
      "15          11  CJ BOX SOBR BR (TOM 20A) 63141 ILUMI TOMADAS I...\n",
      "16          11  CJ BOX SOBR BR (TOM 10A) 63140 ILUMI TOMADAS I...\n",
      "17          11  CJ BOX SOBR BR (1S+TOM 10A) 63200 ILUMI TOMADA...\n",
      "18          11  CJ BOX SOBR BR (2 TOM 20A) 63121 ILUMI TOMADAS...\n",
      "19          11  CJ BOX SOBR BR (2 TOM 10A) 63120 ILUMI TOMADAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from logger import logger\n",
    "\n",
    "# --- Parâmetro ajustável ---\n",
    "LIMIAR = 89          # similaridade entre chaves (fuzz)\n",
    "SENSIBILIDADE = 0.4  # sensibilidade da parte comum (0 a 1)\n",
    "\n",
    "# --- Função para normalizar textos ---\n",
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).upper().strip()\n",
    "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
    "    return texto\n",
    "\n",
    "# --- Carrega o Excel ---\n",
    "df = pd.read_excel(\"pai_filho_variantes.xlsx\")\n",
    "\n",
    "df = df[:20]\n",
    "\n",
    "# --- Cria chave composta ---\n",
    "df[\"Chave\"] = (\n",
    "    df[\"Descrição\"].apply(normalizar) + \" \" +\n",
    "    df[\"Categoria\"].apply(normalizar)\n",
    ")\n",
    "\n",
    "# --- Inicializa controle ---\n",
    "df[\"ID_Variacao\"] = None\n",
    "df[\"Tipo\"] = None\n",
    "df[\"SKU_Pai\"] = None\n",
    "grupo_id = 1\n",
    "usados = set()\n",
    "\n",
    "# --- Agrupamento ---\n",
    "print(\"🔄 Agrupando variações...\")\n",
    "\n",
    "for i, linha in tqdm(df.iterrows(), total=len(df)):\n",
    "    if i in usados:\n",
    "        continue\n",
    "\n",
    "    chave_ref = linha[\"Chave\"]\n",
    "    similares = df.index[df[\"Chave\"].apply(lambda x: fuzz.token_sort_ratio(chave_ref, x) >= LIMIAR)].tolist()\n",
    "\n",
    "    sku_pai = linha.get(\"Sku\", linha.get(\"Código\", i))\n",
    "    df.at[i, \"Tipo\"] = \"PAI\"\n",
    "    df.at[i, \"SKU_Pai\"] = sku_pai\n",
    "    df.at[i, \"ID_Variacao\"] = grupo_id\n",
    "\n",
    "    for idx in similares:\n",
    "        if idx not in usados:\n",
    "            if idx != i:\n",
    "                df.at[idx, \"Tipo\"] = \"FILHO\"\n",
    "                df.at[idx, \"SKU_Pai\"] = sku_pai\n",
    "            df.at[idx, \"ID_Variacao\"] = grupo_id\n",
    "            usados.add(idx)\n",
    "\n",
    "    grupo_id += 1\n",
    "\n",
    "\n",
    "# --- Ordena ---\n",
    "df = df.sort_values(by=[\"ID_Variacao\", \"Tipo\"], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "# --- Função com controle de sensibilidade ---\n",
    "def parte_comum(strings, sensibilidade=SENSIBILIDADE):\n",
    "    if not strings:\n",
    "        return \"\"\n",
    "    base = strings[0]\n",
    "    for s in strings[1:]:\n",
    "        seq = SequenceMatcher(None, base, s)\n",
    "        match = seq.find_longest_match(0, len(base), 0, len(s))\n",
    "        comum = base[match.a: match.a + match.size]\n",
    "\n",
    "        tamanho_medio = (len(base) + len(s)) / 2\n",
    "        proporcao = len(comum) / tamanho_medio\n",
    "\n",
    "        # Mantém só se atingir a sensibilidade mínima\n",
    "        if proporcao >= sensibilidade:\n",
    "            base = comum\n",
    "        else:\n",
    "            base = comum[:int(len(comum) * sensibilidade)]\n",
    "\n",
    "    return base.strip()\n",
    "\n",
    "# --- Cria colunas base e variante ---\n",
    "print(\"🧩 Gerando colunas base e variante...\")\n",
    "df[\"Base\"] = \"\"\n",
    "df[\"Variante\"] = \"\"\n",
    "\n",
    "print(df[['ID_Variacao','Chave']])\n",
    "\n",
    "for gid, grupo in df.groupby(\"ID_Variacao\"):\n",
    "    chaves = grupo[\"Chave\"].tolist()\n",
    "    comum = parte_comum(chaves, SENSIBILIDADE)\n",
    "\n",
    "    for idx, linha in grupo.iterrows():\n",
    "        texto = linha[\"Chave\"]\n",
    "        variante = texto.replace(comum, \"\").strip()\n",
    "        df.at[idx, \"Base\"] = comum\n",
    "        df.at[idx, \"Variante\"] = variante\n",
    "\n",
    "\n",
    "# display(df[['Chave','Base','Variante']])\n",
    "\n",
    "# # --- Salva ---\n",
    "# arquivo_saida = \"base_nome.xlsx\"\n",
    "# df.to_excel(arquivo_saida, index=False)\n",
    "\n",
    "# print(\"✅ Agrupamento concluído com sucesso!\")\n",
    "# print(f\"📂 Arquivo salvo como: {arquivo_saida}\")\n",
    "# print(f\"📦 Total de grupos de variações criados: {grupo_id - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "565d3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iguais: {'TOCO', 'E', 'FERRAMENTAS', 'ACESSORIOS', 'CRV', 'C/PI', 'CHAVE', 'MANUAIS'}\n",
      "Só em A: {'1/4X11/2', 'PHILLIPS', 'FAMASTIL'}\n",
      "Só em B: {'FENDA', 'FOX/FAMASTIL', '3/16X11/2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "a = 'CHAVE PHILLIPS CRV TOCO C/PI 1/4X11/2 FAMASTIL FERRAMENTAS MANUAIS E ACESSORIOS'\n",
    "b= 'CHAVE FENDA TOCO CRV C/PI 3/16X11/2 FOX/FAMASTIL FERRAMENTAS MANUAIS E ACESSORIOS'\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"Similarity score: {fuzz.token_sort_ratio(a, b)}\")\n",
    "\n",
    "# print(process.extract(collection, scorer=fuzz.ratio))\n",
    "\n",
    "\n",
    "set_a = set(a.split())\n",
    "set_b = set(b.split())\n",
    "\n",
    "semelhantes = set_a.intersection(set_b)\n",
    "diferentes_a = set_a - set_b\n",
    "diferentes_b = set_b - set_a\n",
    "\n",
    "print(\"Iguais:\", semelhantes)\n",
    "print(\"Só em A:\", diferentes_a)\n",
    "print(\"Só em B:\", diferentes_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
