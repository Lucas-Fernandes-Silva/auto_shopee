{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4edf798",
   "metadata": {},
   "source": [
    "#Criar um script que fa√ßa:  \n",
    "#Pegue as nfe em xml do email  \n",
    "#Extrai os dados necessarios   \n",
    "#Tratar dados   \n",
    "#Remover materiais pesado E outras notas \n",
    "-TABUAS CABOQUINHO  \n",
    "-CIMENTRO VOTORAN  \n",
    "-Magalu   \n",
    "\n",
    "#Aplicador formula de taxas  \n",
    "#Inserir no template dos marketplaces\n",
    "\n",
    "Ultilizar api do bling para cadastro de itens   (quando tiver)\n",
    "\n",
    "\n",
    "Mercado LIVRE:50% do valor do produto (para produtos at√© R$ 12,50), R$ 6,25 (entre R$ 12,50 e R$ 29), R$ 6,50 (entre R$ 29 e R$ 50) e R$ 6,75 (entre R$ 50 e R$ 79)\n",
    "\n",
    "Comiss√£o de Categoria Constru√ß√£o 12%\n",
    "\n",
    "\n",
    "SHOPE taxa de transa√ß√£o √© sobre o total do produto ent√£o √© 2% de taxa e 18 de comiss√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from imap_tools import MailBox, AND\n",
    "from env import pwd, user\n",
    "from datetime import date, datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"notas/nfes/\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "with MailBox(\"imap.gmail.com\").login(user, pwd, initial_folder=\"INBOX\", ) as mailbox:\n",
    "    list_mail = mailbox.fetch(criteria=AND(date=date.today())\n",
    "\n",
    "    )\n",
    "    for email in list_mail:\n",
    "        for anexo in email.attachments:\n",
    "            if  anexo.filename.lower().endswith(\".xml\"):\n",
    "                file_path = os.path.join(save_folder, anexo.filename)\n",
    "                if not os.path.exists(file_path):   \n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        f.write(anexo.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os XMLs em pastas por Emitente e extrai os produtos para um Excel\n",
    "\n",
    "pasta_origem = \"notas/nfes\"\n",
    "todos_produtos = []\n",
    "\n",
    "\n",
    "def extrai_dados(caminho_arquivo):\n",
    "    produtos = []\n",
    "    tree = ET.parse(caminho_arquivo)\n",
    "    root = tree.getroot()\n",
    "    ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "    data_str = root.find(\".//ns:ide/ns:dhEmi\", ns).text\n",
    "    data_emissao = datetime.fromisoformat(data_str)\n",
    "\n",
    "    \n",
    "    natOp = root.find(\".//ns:ide/ns:natOp\", ns)\n",
    "    if natOp is not None and natOp.text.strip().upper() == 'BONIFICACAO, DOACAO OU BRINDE':\n",
    "        return [] \n",
    "    \n",
    "    for det in root.findall(\".//ns:det\", ns):   \n",
    "        produto = {}\n",
    "        temp_codigo = det.find(\"./ns:prod/ns:cProd\", ns).text\n",
    "        if not \"-\" in temp_codigo:\n",
    "            produto ['Codigo Produto'] = temp_codigo\n",
    "        produto ['Descri√ß√£o'] = det.find(\"./ns:prod/ns:xProd\", ns).text\n",
    "        produto ['Valor_unit√°rio'] = det.find(\"./ns:prod/ns:vUnCom\", ns).text\n",
    "        produto ['C√≥digo de Barras'] = det.find(\"./ns:prod/ns:cEAN\", ns).text \n",
    "        produto ['Sku'] = produto['C√≥digo de Barras']\n",
    "        if produto['Sku'] == 'SEM GTIN':\n",
    "            produto['Sku'] = produto['Descri√ß√£o']\n",
    "        produto ['Fornecedor'] = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "        produto ['Data Emiss√£o'] = data_emissao\n",
    "\n",
    "        produtos.append(produto)\n",
    "    return produtos\n",
    "\n",
    "\n",
    "# Percorre todos os arquivos da pasta\n",
    "for arquivo in os.listdir(pasta_origem):\n",
    "    if arquivo.lower().endswith(\".xml\"):\n",
    "        caminho_arquivo = os.path.join(pasta_origem, arquivo)\n",
    "\n",
    "        try:\n",
    "            # Abre e parseia o XML\n",
    "            tree = ET.parse(caminho_arquivo)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Define namespace\n",
    "            ns = {\"ns\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "\n",
    "            # Busca o CNPJ do emitente\n",
    "            cnpj_emitente = root.find(\".//ns:emit/ns:CNPJ\", ns)\n",
    "            cnpj_emitente\n",
    "            if cnpj_emitente is None:\n",
    "                print(f\"‚ö†Ô∏è CNPJ n√£o encontrado em {arquivo}\")\n",
    "                continue\n",
    "\n",
    "            cnpj_emitente = cnpj_emitente.text\n",
    "\n",
    "            produtos = extrai_dados(caminho_arquivo)\n",
    "            todos_produtos.extend(produtos)              \n",
    "\n",
    "\n",
    "            emitente = root.find(\".//ns:emit/ns:xNome\", ns).text\n",
    "            \n",
    "            pasta_destino = os.path.join(\"notas/\")\n",
    "\n",
    "            # Cria a pasta se n√£o existir\n",
    "            os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "            # Copia o arquivo para a pasta\n",
    "            shutil.copy(caminho_arquivo, pasta_destino)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" {arquivo}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "fornecedores_pesados = [\n",
    "    'IND E COM DE TUBOS E CONEXOES FORT.COM',\n",
    "    'VOTORANTIM CIMENTOS SA',\n",
    "    'CABOQUINHO MATERIAIS PARA CONSTRUCAO'\n",
    "]\n",
    "\n",
    "\n",
    "produtos = pd.DataFrame(todos_produtos)\n",
    "produtos = produtos[~produtos['Fornecedor'].isin(fornecedores_pesados)]\n",
    "produtos = produtos.sort_values(by=\"Data Emiss√£o\", ascending=False)\n",
    "\n",
    "produtos = produtos.drop_duplicates(subset='Codigo Produto', keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos['Fornecedor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f384208",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d981c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_excel('upseller_template.xlsx')\n",
    "produtos = read[-1:]\n",
    "\n",
    "\n",
    "for  index, produto in produtos.iterrows():\n",
    "    # fornecedor = produto['Fornecedor']\n",
    "    # codigo_produto = produto['Codigo Produto']\n",
    "    # descricao = produto['Descri√ß√£o']\n",
    "    try:\n",
    "    #     if fornecedor == 'CONSTRUDIGI DISTRIBUIDORA DE MATERIAIS PARA CONSTRUCAO LTDA':   \n",
    "    #         url = f'https://www.construdigi.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     elif fornecedor == 'M.S.B. COMERCIO DE MATERIAIS PARA CONSTRUCAO':\n",
    "    #         url = f'https://msbitaqua.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     elif fornecedor == \"CONSTRUJA DISTR. DE MATERIAIS P/ CONSTRU\":\n",
    "    #         url = f'https://www.construja.com.br/produto/{codigo_produto}/{descricao}'\n",
    "    #     else:\n",
    "    #         print('Indisponivel')\n",
    "    #         continue\n",
    "        \n",
    "        url = 'https://construja.com.br/produto/101223/estrela-tapa-furo-ll-20mm'\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        script = soup.find(\"script\", type=\"application/json\")\n",
    "        data = json.loads(script.string) if script else {}\n",
    "       \n",
    "        extrai = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"produto\", {})\n",
    "        comprimento = extrai.get(\"comprimento\")\n",
    "\n",
    "        url_img = data.get(\"props\", {}).get(\"pageProps\", {}).get(\"seo\", {}).get(\"imageUrl\", 'N√£o disponivel')\n",
    "        marca = next((p.get(\"desc\") for p in extrai.get(\"dimensoes\", []) if p.get(\"label\") == \"MARCA\"), \"N√£o dispon√≠vel\")\n",
    "        categoria = next((p.get(\"desc\") for p in extrai.get(\"dimensoes\", []) if p.get(\"label\") == \"SUB CATEGORIA\"), \"N√£o dispon√≠vel\")\n",
    "        print(categoria)\n",
    "        peso = extrai.get(\"pesoBruto\", \"N√£o dispon√≠vel\")\n",
    "        if codigo_barras == 'SEM GTIN':\n",
    "            codigo_barras = extrai.get(\"codBarra\", \"SEM GTIN\")\n",
    "        produtos.at[index, 'C√≥digo de Barras'] = codigo_barras\n",
    "        produtos.at[index, 'Peso'] = peso\n",
    "        produtos.at[index, \"Marca\"] = marca\n",
    "        produtos.at[index, 'Url Imagem'] = url_img\n",
    "        \n",
    "        print(produto['Descri√ß√£o'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from env import fornecedores_noweb_scapping\n",
    "\n",
    "# === 1. Carregar o arquivo ===\n",
    "df = pd.read_excel('produtos.xlsx')\n",
    "\n",
    "# === 2. Fun√ß√£o para limpar e normalizar texto ===\n",
    "def limpar_texto(txt):\n",
    "    if not isinstance(txt, str):\n",
    "\n",
    "        return \"\"\n",
    "    # Remove acentos\n",
    "    txt = unicodedata.normalize('NFD', txt)\n",
    "    txt = txt.encode('ascii', 'ignore').decode('utf-8')\n",
    "    # Converte para mai√∫sculas\n",
    "    txt = txt.upper()\n",
    "    # Remove caracteres especiais\n",
    "    txt = re.sub(r'[^A-Z0-9 ]', '', txt)\n",
    "    # Remove espa√ßos duplicados\n",
    "    txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "    return txt\n",
    "\n",
    "\n",
    "# === 3. Lista de marcas fixas (for√ßadas a fazer parte da an√°lise) ===\n",
    "marcas_adicionais = [\n",
    "    'SHIVA','BRASCOLA','FERTAK','NATICON','NOBRE','ADELBRAS','STA MARINA','FIRMEZA','OLIPLAS','STAM', 'R.C.A','CORONA','TOP FIO',\n",
    "    'MAKITA','REXON','SOPRANO','FAST LUB','ACQUA','KIAN','SOUDAL','DEPLAST','TATU','GRENDHA', 'PANASONIC','PAULICEIA','MORIA',\n",
    "    'ALLTAPE','PLASTILIT','TITANIUM','FERRARI','NEGREIRA','RADIAL','BLUMENAU','J.F METAIS','ART METAIS','LONAX', 'GHEL PLUS',\n",
    "    'CHEMICOLOR','SANY','PROAQUA','BICROM','WAGO','TECHNA','METASUL','GARAPEIRA','ROCO','PRO FOAM','DURACELL','POLIBEL','AGELUX',\n",
    "    'REMOX','RORATO','WAVES','LEGRAND','PAPAIZ','AGELUZ','IMPERIAL','HYDRA','KITUBO','NETTE','SANLIMP', 'EMA METAIS','M&M'\n",
    "    'BEARS','ADTEX','GALO','PEGAFORTE','EMAVE','ELGIN','LUCONI','VEGA','MUNDIAL','DELTA', 'COBRECOM','PLASTBIG','FERE','SATA',\n",
    "    'ALUMBRA', 'FIOLUX','PACETTA','ITAMBE','PEXCEL','EMAVA','KADESH','IBERE','GOLD','PERLEX','IMA','SAFETY','PIAL','PLASTIK',\n",
    "    'OUROLUX', 'LED BEE','BELZER','PROTEG','NASTRO','FJ FERR', 'SAO RAFAEL', 'STILLUS','FLASH LIMP', 'ZUMPLAST','REDY','PRIMETECH',\n",
    "    'SECALUX', 'PLASTIC','SUPER BONDER', 'ARTPLAS','FABER CASTELL','GUARANI','DEWALT','ALUREM','PERFIX ','STELL','FERROX','USAF',\n",
    "    'INJET','CMK','BEARS','MINASUL','DEGOMASTER','SIENA'\n",
    "]\n",
    "marcas_adicionais = [limpar_texto(m) for m in marcas_adicionais]\n",
    "\n",
    "\n",
    "# === 4. Dicion√°rio de sin√¥nimos / varia√ß√µes ===\n",
    "mapa_variacoes = {\n",
    "    'TRAMONTINA': ['TRAMON', 'TRAMONTINA', 'TRAMONTINA ELE', 'TRAMONTINA GARI', 'TRAMONTINA MULT', 'TRAM'],\n",
    "    'JOMARCA': ['JOMARCA', 'JOMARC', 'JOMARCA JMC', 'JMC'],\n",
    "    'NEW FIX': ['NEW FIX', 'NEWFIX', 'NEW-FIX', 'NEW F','PARAF CHIPBOARD CHATA PHS','PARAF SEX.ROS.SOBERBA'],\n",
    "    'NOVA': ['NOVA TINTAS', 'NOVA'],\n",
    "    'DRYKO': ['DRYKO', 'DRYKOPRIMER'],\n",
    "    'SIKA': ['SIKATOP', 'SIKA'],\n",
    "    'BRASFORT': ['BRASF', 'BRASFORT'],\n",
    "    'ILUMI': ['ILUM', 'ILUMI'],\n",
    "    'DENVER': ['DENVER','DENVERIMPER', 'DENVERLAJE','DENVERTEC','DENVERCRILL', 'DENVERFITA','DENVERFIX'],\n",
    "    'THOMPSOM': ['THOMPSOM', 'THOMP'],\n",
    "    'PEGAFORTE': ['PEGAFORTE', 'PEGA FORTE'],\n",
    "    'CALHA FORTE': ['CALHA FORTE', 'CALHA FORT'],\n",
    "    'VEDACIT': ['VEDACIT', 'BIANCO'],\n",
    "    'LORENZETTI': ['LOREN','LORENZETTI','ORIG.L&C D','.PMR D.','.L&C '],\n",
    "    'KADESH': ['BOT FLEX ELASTICO PRETA BI']\n",
    "}\n",
    "\n",
    "\n",
    "# === 5. Montar lista final de marcas conhecidas ===\n",
    "marcas_planilha = df['Marca'].dropna().unique().tolist()\n",
    "marcas_planilha.remove('5+')\n",
    "marcas_planilha = [limpar_texto(m) for m in marcas_planilha if isinstance(m, str) and m.strip()]\n",
    "\n",
    "# Combinar todas\n",
    "marcas = list(set(marcas_planilha + marcas_adicionais))\n",
    "\n",
    "# Adicionar tamb√©m as varia√ß√µes do mapa\n",
    "for marca_principal, variacoes in mapa_variacoes.items():\n",
    "    marcas.append(marca_principal)\n",
    "    marcas.extend([limpar_texto(v) for v in variacoes])\n",
    "\n",
    "marcas = list(set(marcas))\n",
    "\n",
    "\n",
    "# === 7. Fun√ß√£o para detectar marca na descri√ß√£o ===\n",
    "def detectar_marca(descricao):\n",
    "    desc_limpa = limpar_texto(descricao)\n",
    "\n",
    "    # Verifica varia√ß√µes conhecidas primeiro\n",
    "    for marca_padrao, variacoes in mapa_variacoes.items():\n",
    "        for v in variacoes:\n",
    "            if limpar_texto(v) in desc_limpa:\n",
    "                return marca_padrao\n",
    "\n",
    "    # Caso n√£o encontre nas varia√ß√µes, busca direta na lista geral\n",
    "    for marca in marcas:\n",
    "        if marca and marca in desc_limpa:\n",
    "            return marca\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "df_filtrado = df.copy()\n",
    "\n",
    "# === 8. Detectar e preencher marcas ausentes ===\n",
    "df_filtrado['Marca Detectada'] = df_filtrado['Descri√ß√£o'].apply(detectar_marca)\n",
    "\n",
    "# Preenche apenas onde est√° vazio\n",
    "df_filtrado['Marca'] = df_filtrado['Marca'].fillna(df_filtrado['Marca Detectada'])\n",
    "\n",
    "df_filtrado['Marca'] = df_filtrado['Marca'].fillna('GEN√âRICO')\n",
    "# Atualiza no dataframe principal\n",
    "df.update(df_filtrado)\n",
    "\n",
    "\n",
    "# === 9. Salvar resultado ===\n",
    "df.to_excel('produtos_com_marcas.xlsx', index=False)\n",
    "\n",
    "# === 10. Relat√≥rio simples ===\n",
    "print(\"‚úÖ Processamento conclu√≠do!\")\n",
    "print(f\"Total de produtos analisados: {len(df_filtrado)}\")\n",
    "print(f\"Marcas detectadas automaticamente: {df_filtrado['Marca Detectada'].notna().sum()}\")\n",
    "\n",
    "# Top 10 marcas mais detectadas\n",
    "print(\"\\nTop marcas detectadas:\")\n",
    "print(df_filtrado['Marca Detectada'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "df = pd.read_excel('pai_filho_variantes.xlsx')\n",
    "\n",
    "# --- Fun√ß√£o para normalizar ---\n",
    "def normalizar(texto):\n",
    "    texto = str(texto).lower().strip()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    return texto\n",
    "\n",
    "df[\"chave_norm\"] = df[\"chave\"].apply(normalizar)\n",
    "\n",
    "# --- Fun√ß√£o para encontrar a base e varia√ß√£o dentro de um grupo ---\n",
    "def extrair_base_variacao(grupo_df):\n",
    "    textos = grupo_df[\"chave_norm\"].tolist()\n",
    "    palavras = [set(t.split()) for t in textos]\n",
    "\n",
    "    comuns = set.intersection(*palavras) \n",
    "    bases, variacoes = [], []\n",
    "    for texto in textos:\n",
    "        palavras_texto = texto.split()\n",
    "        variacao = [p for p in palavras_texto if p not in comuns]\n",
    "        base = [p for p in palavras_texto if p in comuns]\n",
    "        bases.append(\" \".join(base))\n",
    "        variacoes.append(\" \".join(variacao))\n",
    "    \n",
    "    grupo_df[\"base\"] = bases\n",
    "    grupo_df[\"variacao\"] = variacoes\n",
    "    return grupo_df\n",
    "\n",
    "# --- Aplica por grupo ---\n",
    "df_resultado = (\n",
    "    df.groupby(\"ID_Variacao\", group_keys=False)\n",
    "      .apply(lambda g: extrair_base_variacao(g.copy()))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_resultado.to_excel('base_nome.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12ab5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Agrupando varia√ß√µes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 1403.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Gerando colunas base e variante...\n",
      "   ID_Variacao                                              Chave\n",
      "0            1         FITA CREPE 48X50 USO GERAL MASK FITA CREPE\n",
      "1            1         FITA CREPE 24X50 USO GERAL MASK FITA CREPE\n",
      "2            2   VALV RETENCAO ESG 100/75 ESTRELA CONEXOES ESGOTO\n",
      "3            2    VALV RETENCAO ESG 50/40 ESTRELA CONEXOES ESGOTO\n",
      "4            3  VELA FILTRO GRAVIDADE V/C CRISTALINA DIVERSOS ...\n",
      "5            4  CHAVE PHILLIPS CRV TOCO C/PI 1/4X11/2 FAMASTIL...\n",
      "6            5  CHAVE FENDA TOCO CRV C/PI 3/16X11/2 FOX/FAMAST...\n",
      "7            6  LAMP LED ALTA POT 30W-2400LM 6500K GALAXY LAMP...\n",
      "8            6  LAMP LED ALTA POT 40W-3200LM 6500K GALAXY LAMP...\n",
      "9            6  LAMP LED ALTA POT 50W-4000LM 6500K GALAXY LAMP...\n",
      "10           6  LAMP LED ALTA POT 20W-1600LM 6500K GALAXY LAMP...\n",
      "11           7  LAMP LED ALTA POT 50W-4000LM 6500K FOXLUX LAMP...\n",
      "12           8  LAMP LED ALTA POT 50W-4000LM 6500K AVANT LAMPADAS\n",
      "13           9         CX DESC S/E 6/9L BR ALUMASA CAIXA DESCARGA\n",
      "14          10  RECEPTACULO E27 1451 THOMPSON LUMINARIAS SUPOR...\n",
      "15          11  CJ BOX SOBR BR (TOM 20A) 63141 ILUMI TOMADAS I...\n",
      "16          11  CJ BOX SOBR BR (TOM 10A) 63140 ILUMI TOMADAS I...\n",
      "17          11  CJ BOX SOBR BR (1S+TOM 10A) 63200 ILUMI TOMADA...\n",
      "18          11  CJ BOX SOBR BR (2 TOM 20A) 63121 ILUMI TOMADAS...\n",
      "19          11  CJ BOX SOBR BR (2 TOM 10A) 63120 ILUMI TOMADAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from logger import logger\n",
    "\n",
    "# --- Par√¢metro ajust√°vel ---\n",
    "LIMIAR = 89          # similaridade entre chaves (fuzz)\n",
    "SENSIBILIDADE = 0.4  # sensibilidade da parte comum (0 a 1)\n",
    "\n",
    "# --- Fun√ß√£o para normalizar textos ---\n",
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).upper().strip()\n",
    "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
    "    return texto\n",
    "\n",
    "# --- Carrega o Excel ---\n",
    "df = pd.read_excel(\"pai_filho_variantes.xlsx\")\n",
    "\n",
    "df = df[:20]\n",
    "\n",
    "# --- Cria chave composta ---\n",
    "df[\"Chave\"] = (\n",
    "    df[\"Descri√ß√£o\"].apply(normalizar) + \" \" +\n",
    "    df[\"Categoria\"].apply(normalizar)\n",
    ")\n",
    "\n",
    "# --- Inicializa controle ---\n",
    "df[\"ID_Variacao\"] = None\n",
    "df[\"Tipo\"] = None\n",
    "df[\"SKU_Pai\"] = None\n",
    "grupo_id = 1\n",
    "usados = set()\n",
    "\n",
    "# --- Agrupamento ---\n",
    "print(\"üîÑ Agrupando varia√ß√µes...\")\n",
    "\n",
    "for i, linha in tqdm(df.iterrows(), total=len(df)):\n",
    "    if i in usados:\n",
    "        continue\n",
    "\n",
    "    chave_ref = linha[\"Chave\"]\n",
    "    similares = df.index[df[\"Chave\"].apply(lambda x: fuzz.token_sort_ratio(chave_ref, x) >= LIMIAR)].tolist()\n",
    "\n",
    "    sku_pai = linha.get(\"Sku\", linha.get(\"C√≥digo\", i))\n",
    "    df.at[i, \"Tipo\"] = \"PAI\"\n",
    "    df.at[i, \"SKU_Pai\"] = sku_pai\n",
    "    df.at[i, \"ID_Variacao\"] = grupo_id\n",
    "\n",
    "    for idx in similares:\n",
    "        if idx not in usados:\n",
    "            if idx != i:\n",
    "                df.at[idx, \"Tipo\"] = \"FILHO\"\n",
    "                df.at[idx, \"SKU_Pai\"] = sku_pai\n",
    "            df.at[idx, \"ID_Variacao\"] = grupo_id\n",
    "            usados.add(idx)\n",
    "\n",
    "    grupo_id += 1\n",
    "\n",
    "\n",
    "# --- Ordena ---\n",
    "df = df.sort_values(by=[\"ID_Variacao\", \"Tipo\"], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "# --- Fun√ß√£o com controle de sensibilidade ---\n",
    "def parte_comum(strings, sensibilidade=SENSIBILIDADE):\n",
    "    if not strings:\n",
    "        return \"\"\n",
    "    base = strings[0]\n",
    "    for s in strings[1:]:\n",
    "        seq = SequenceMatcher(None, base, s)\n",
    "        match = seq.find_longest_match(0, len(base), 0, len(s))\n",
    "        comum = base[match.a: match.a + match.size]\n",
    "\n",
    "        tamanho_medio = (len(base) + len(s)) / 2\n",
    "        proporcao = len(comum) / tamanho_medio\n",
    "\n",
    "        # Mant√©m s√≥ se atingir a sensibilidade m√≠nima\n",
    "        if proporcao >= sensibilidade:\n",
    "            base = comum\n",
    "        else:\n",
    "            base = comum[:int(len(comum) * sensibilidade)]\n",
    "\n",
    "    return base.strip()\n",
    "\n",
    "# --- Cria colunas base e variante ---\n",
    "print(\"üß© Gerando colunas base e variante...\")\n",
    "df[\"Base\"] = \"\"\n",
    "df[\"Variante\"] = \"\"\n",
    "\n",
    "print(df[['ID_Variacao','Chave']])\n",
    "\n",
    "for gid, grupo in df.groupby(\"ID_Variacao\"):\n",
    "    chaves = grupo[\"Chave\"].tolist()\n",
    "    comum = parte_comum(chaves, SENSIBILIDADE)\n",
    "\n",
    "    for idx, linha in grupo.iterrows():\n",
    "        texto = linha[\"Chave\"]\n",
    "        variante = texto.replace(comum, \"\").strip()\n",
    "        df.at[idx, \"Base\"] = comum\n",
    "        df.at[idx, \"Variante\"] = variante\n",
    "\n",
    "\n",
    "# display(df[['Chave','Base','Variante']])\n",
    "\n",
    "# # --- Salva ---\n",
    "# arquivo_saida = \"base_nome.xlsx\"\n",
    "# df.to_excel(arquivo_saida, index=False)\n",
    "\n",
    "# print(\"‚úÖ Agrupamento conclu√≠do com sucesso!\")\n",
    "# print(f\"üìÇ Arquivo salvo como: {arquivo_saida}\")\n",
    "# print(f\"üì¶ Total de grupos de varia√ß√µes criados: {grupo_id - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "565d3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iguais: {'TOCO', 'E', 'FERRAMENTAS', 'ACESSORIOS', 'CRV', 'C/PI', 'CHAVE', 'MANUAIS'}\n",
      "S√≥ em A: {'1/4X11/2', 'PHILLIPS', 'FAMASTIL'}\n",
      "S√≥ em B: {'FENDA', 'FOX/FAMASTIL', '3/16X11/2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "a = 'CHAVE PHILLIPS CRV TOCO C/PI 1/4X11/2 FAMASTIL FERRAMENTAS MANUAIS E ACESSORIOS'\n",
    "b= 'CHAVE FENDA TOCO CRV C/PI 3/16X11/2 FOX/FAMASTIL FERRAMENTAS MANUAIS E ACESSORIOS'\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"Similarity score: {fuzz.token_sort_ratio(a, b)}\")\n",
    "\n",
    "# print(process.extract(collection, scorer=fuzz.ratio))\n",
    "\n",
    "\n",
    "set_a = set(a.split())\n",
    "set_b = set(b.split())\n",
    "\n",
    "semelhantes = set_a.intersection(set_b)\n",
    "diferentes_a = set_a - set_b\n",
    "diferentes_b = set_b - set_a\n",
    "\n",
    "print(\"Iguais:\", semelhantes)\n",
    "print(\"S√≥ em A:\", diferentes_a)\n",
    "print(\"S√≥ em B:\", diferentes_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
